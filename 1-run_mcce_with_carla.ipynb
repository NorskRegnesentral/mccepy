{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n",
      "balance on test set 0.23883245958934032, balance on test set 0.2408256880733945\n",
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/carla/models/catalog/ANN_TORCH/model_ann.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4668 Acc: 0.7734\n",
      "\n",
      "test Loss: 0.4055 Acc: 0.8005\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.3946 Acc: 0.8121\n",
      "\n",
      "test Loss: 0.3910 Acc: 0.8189\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.3784 Acc: 0.8222\n",
      "\n",
      "test Loss: 0.3747 Acc: 0.8226\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.3655 Acc: 0.8290\n",
      "\n",
      "test Loss: 0.3600 Acc: 0.8324\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.3535 Acc: 0.8343\n",
      "\n",
      "test Loss: 0.3505 Acc: 0.8373\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.3460 Acc: 0.8372\n",
      "\n",
      "test Loss: 0.3472 Acc: 0.8389\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.3431 Acc: 0.8387\n",
      "\n",
      "test Loss: 0.3450 Acc: 0.8402\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.3405 Acc: 0.8402\n",
      "\n",
      "test Loss: 0.3435 Acc: 0.8384\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.3404 Acc: 0.8389\n",
      "\n",
      "test Loss: 0.3376 Acc: 0.8396\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.3348 Acc: 0.8421\n",
      "\n",
      "test Loss: 0.3421 Acc: 0.8400\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.3348 Acc: 0.8411\n",
      "\n",
      "test Loss: 0.3362 Acc: 0.8426\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.3345 Acc: 0.8401\n",
      "\n",
      "test Loss: 0.3339 Acc: 0.8435\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.3313 Acc: 0.8430\n",
      "\n",
      "test Loss: 0.3334 Acc: 0.8426\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.3296 Acc: 0.8442\n",
      "\n",
      "test Loss: 0.3353 Acc: 0.8435\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.3324 Acc: 0.8436\n",
      "\n",
      "test Loss: 0.3366 Acc: 0.8395\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.3311 Acc: 0.8431\n",
      "\n",
      "test Loss: 0.3449 Acc: 0.8354\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.3299 Acc: 0.8426\n",
      "\n",
      "test Loss: 0.3344 Acc: 0.8393\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.3296 Acc: 0.8435\n",
      "\n",
      "test Loss: 0.3302 Acc: 0.8430\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.3274 Acc: 0.8442\n",
      "\n",
      "test Loss: 0.3300 Acc: 0.8471\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.3295 Acc: 0.8434\n",
      "\n",
      "test Loss: 0.3283 Acc: 0.8449\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from carla.data.catalog import OnlineCatalog\n",
    "from carla.models.catalog import MLModelCatalog\n",
    "from carla.models.negative_instances import predict_negative_instances\n",
    "\n",
    "import torch\n",
    "\n",
    "from mcce import MCCE\n",
    "\n",
    "data_name = \"adult\"\n",
    "# data_name = 'give_me_some_credit'\n",
    "# data_name = 'compas'\n",
    "K = 10000\n",
    "n_test = 100\n",
    "seed = 1\n",
    "\n",
    "# for data_name in dataset:\n",
    "dataset = OnlineCatalog(data_name)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "ml_model = MLModelCatalog(\n",
    "        dataset, \n",
    "        model_type=\"ann\", \n",
    "        load_online=False, \n",
    "        backend=\"pytorch\"\n",
    "    )\n",
    "\n",
    "if data_name == 'adult':\n",
    "    ml_model.train(\n",
    "    learning_rate=0.002,\n",
    "    epochs=20,\n",
    "    batch_size=1024,\n",
    "    hidden_size=[18, 9, 3],\n",
    "    force_train=True, # don't forget to add this or it might load an older model from disk\n",
    "    )\n",
    "elif data_name == 'give_me_some_credit':\n",
    "    ml_model.train(\n",
    "    learning_rate=0.002,\n",
    "    epochs=20,\n",
    "    batch_size=2048,\n",
    "    hidden_size=[18, 9, 3],\n",
    "    force_train=True, # don't forget to add this or it might load an older model from disk\n",
    "    )\n",
    "elif data_name == 'compas':\n",
    "    ml_model.train(\n",
    "    learning_rate=0.002,\n",
    "    epochs=25,\n",
    "    batch_size=25,\n",
    "    hidden_size=[18, 9, 3],\n",
    "    force_train=True, # don't forget to add this or it might load an older model from disk\n",
    "    )\n",
    "\n",
    "# (2) Find unhappy customers and choose which ones to make counterfactuals for\n",
    "\n",
    "factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "test_factual = factuals.iloc[:n_test]\n",
    "# test_factual_inverse = dataset.inverse_transform(test_factual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39476\n",
      "48832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9356"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(factuals.shape[0])\n",
    "print(dataset.df.shape[0])\n",
    "\n",
    "48832 - 39476"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = dataset.target\n",
    "features_and_response = dataset.df.columns\n",
    "cont_feat = dataset.continuous\n",
    "cat_feat = [x for x in features_and_response if x not in cont_feat] #  these have new names since encode_normalize_order_factuals()\n",
    "\n",
    "if data_name == 'adult': \n",
    "    fixed_features = ['age', 'sex_Male']\n",
    "    immutables = ['age', 'sex']\n",
    "elif data_name == 'give_me_some_credit':\n",
    "    fixed_features = ['age']\n",
    "    immutables = ['age']\n",
    "elif data_name == 'compas':\n",
    "    fixed_features = ['age', 'sex_Male', 'race_Other']\n",
    "    immutables = ['age', 'sex', 'race']\n",
    "\n",
    "#  Create dtypes for MCCE()\n",
    "dtypes = dict([(x, \"float\") for x in cont_feat])\n",
    "for x in cat_feat:\n",
    "    dtypes[x] = \"category\"\n",
    "df = (dataset.df).astype(dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_factual.drop(y_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "results = []\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "mcce = MCCE(fixed_features=fixed_features, immutables=immutables, model=ml_model, seed=1, continuous=cont_feat, categorical=cat_feat)\n",
    "\n",
    "mcce.fit(df.drop(y_col, axis=1), dtypes)\n",
    "\n",
    "synth_df = mcce.generate(test_factual.drop(y_col, axis=1), k=K)\n",
    "\n",
    "mcce.postprocess(data=df, synth=synth_df, test=test_factual, response=y_col, \\\n",
    "    inverse_transform=dataset.inverse_transform, cutoff=0.5)\n",
    "\n",
    "timing = time.time() - start\n",
    "# print(timing)\n",
    "\n",
    "mcce.results_sparse['time (seconds)'] = timing\n",
    "\n",
    "results.append([mcce.results_sparse.L0.mean(), mcce.results_sparse.L2.mean(), mcce.results_sparse.feasibility.mean(),\\\n",
    "     mcce.results_sparse.violation.mean(), mcce.results_sparse.shape[0], timing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f\"{data_name}_mcce_results_k_{K}_n_{n_test}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcce.results_sparse.to_csv(f\"/nr/samba/user/anr/pkg/MCCE_Python/Results/{data_name}_mcce_results_k_{K}_n_{n_test}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = pd.DataFrame(results, columns=['L0', 'L2', 'feasibility', 'violation', 'NCE', 'timing'])\n",
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcce.df_columns = df.columns.tolist()\n",
    "# mcce.n_df_rows, mcce.n_df_columns = np.shape(df)\n",
    "# mcce.df_dtypes = dtypes\n",
    "# mcce.mutable_features = [col for col in mcce.df_columns if (col not in mcce.fixed_features)]\n",
    "# mcce.cont_feat = [feat for feat in dtypes.keys() if dtypes[feat] != 'category']\n",
    "\n",
    "# mcce.n_fixed, mcce.n_mutable = len(mcce.fixed_features), len(mcce.mutable_features)\n",
    "\n",
    "# # column indices of mutable features\n",
    "# mcce.visit_sequence = [index for index, col in enumerate(mcce.df_columns) if (col in mcce.fixed_features)] # if (col in mccemutable_features)\n",
    "# for index, col in enumerate(mcce.df_columns):\n",
    "#     if col in mcce.mutable_features:\n",
    "#         mcce.visit_sequence.append(index)\n",
    "\n",
    "# # convert indices to column names\n",
    "# mcce.visit_sequence = [mcce.df_columns[i] for i in mcce.visit_sequence]\n",
    "\n",
    "# mcce.visited_columns = [col for col in mcce.df_columns if col in mcce.visit_sequence]\n",
    "# mcce.visit_sequence = pd.Series([mcce.visit_sequence.index(col) for col in mcce.visited_columns], index=mcce.visited_columns)\n",
    "\n",
    "# # create list of methods to use - currently only cart implemented\n",
    "# mcce.method = []\n",
    "# for col in mcce.visited_columns:\n",
    "#     if col in mcce.fixed_features:\n",
    "#         mcce.method.append('sample') # these will be fit but not sampled \n",
    "#     else:\n",
    "#         mcce.method.append('cart')\n",
    "# mcce.method = pd.Series(mcce.method, index=mcce.df_columns)\n",
    "\n",
    "# # predictor_matrix_validator:\n",
    "# mcce.predictor_matrix = np.zeros([len(mcce.visit_sequence), len(mcce.visit_sequence)], dtype=int)\n",
    "# mcce.predictor_matrix = pd.DataFrame(mcce.predictor_matrix, index=mcce.visit_sequence.index, columns=mcce.visit_sequence.index)\n",
    "# visited_columns = []\n",
    "# for col, _ in mcce.visit_sequence.sort_values().iteritems():\n",
    "#     mcce.predictor_matrix.loc[col, visited_columns] = 1\n",
    "#     visited_columns.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cart import CARTMethod\n",
    "# from sample import SampleMethod\n",
    "\n",
    "# METHODS_MAP = {'cart': CARTMethod, 'sample': SampleMethod}\n",
    "\n",
    "# mcce.saved_methods = {}\n",
    "# mcce.trees = {}\n",
    "\n",
    "# # train\n",
    "# mcce.predictor_matrix_columns = mcce.predictor_matrix.columns.to_numpy()\n",
    "# for col, _ in mcce.visit_sequence.sort_values().iteritems():\n",
    "#     # initialise the method\n",
    "#     col_method = METHODS_MAP[mcce.method[col]](dtype=mcce.df_dtypes[col], random_state=mcce.seed)\n",
    "    \n",
    "#     # fit the method\n",
    "#     col_predictors = mcce.predictor_matrix_columns[mcce.predictor_matrix.loc[col].to_numpy() == 1]\n",
    "    \n",
    "#     # print(df[col_predictors])\n",
    "#     # print(df[col])\n",
    "\n",
    "#     col_method.fit(X_df=df[col_predictors], y_df=df[col])\n",
    "    \n",
    "#     if col == 'capital-gain':\n",
    "#         print(col)\n",
    "#         print(col_method.leaves_y_dict)\n",
    "\n",
    "#     # save the method\n",
    "#     if mcce.method[col] == 'cart':\n",
    "#         mcce.trees[col] = col_method.leaves_y_dict\n",
    "#     mcce.saved_methods[col] = col_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 100\n",
    "# test = test_factual.drop(y_col, axis=1)\n",
    "# n_test = test.shape[0]\n",
    "\n",
    "# # create data set with the fixed features repeated k times\n",
    "# synth_df = test[mcce.fixed_features]\n",
    "# synth_df = pd.concat([synth_df] * k)\n",
    "# synth_df.sort_index(inplace=True)\n",
    "\n",
    "# # repeat 0 for mutable features k times\n",
    "# synth_df_mutable = pd.DataFrame(data=np.zeros([k * n_test, mcce.n_mutable]), columns=mcce.mutable_features, index=synth_df.index)\n",
    "\n",
    "# synth_df = pd.concat([synth_df, synth_df_mutable], axis=1)\n",
    "# # print(synth_df.head(10))\n",
    "# start_time = time.time()\n",
    "# for col in mcce.mutable_features:\n",
    "#     print(col)\n",
    "#     # reload the method\n",
    "#     col_method = mcce.saved_methods[col]\n",
    "#     # print(col_method)\n",
    "#     # predict with the method\n",
    "#     col_predictors = mcce.predictor_matrix_columns[mcce.predictor_matrix.loc[col].to_numpy() == 1]\n",
    "#     # print(col_predictors)\n",
    "#     # print(col_predictors)\n",
    "\n",
    "#     # print(synth_df[col_predictors])\n",
    "#     synth_df[col] = col_method.predict(synth_df[col_predictors])\n",
    "#     # print(synth_df[col][0:10])\n",
    "#     # if col == 'education-num':\n",
    "#     #     print(synth_df)\n",
    "#     X_test_df = synth_df[col_predictors]\n",
    "#     # print(X_test_df)\n",
    "#     X_test_df, _ = col_method.prepare_dfs(X_df=X_test_df, normalise_num_cols=False, one_hot_cat_cols=False, fit=False)\n",
    "#     # if col == 'education-num':\n",
    "#     #     print(X_test_df)\n",
    "#     # print(col_method.cart.get_params())\n",
    "#     # print(col_method.cart.tree_)\n",
    "    \n",
    "#     # predict the leaves and for each leaf randomly sample from the observed values\n",
    "#     X_test = X_test_df.to_numpy()\n",
    "#     # if col == 'education-num':\n",
    "#     #     print(X_test[0])\n",
    "#     leaves_pred = col_method.cart.apply(X_test)\n",
    "#     # print(leaves_pred)\n",
    "#     y_pred = np.zeros(len(leaves_pred), dtype=object)\n",
    "\n",
    "#     leaves_pred_index_df = pd.DataFrame({'leaves_pred': leaves_pred, 'index': range(len(leaves_pred))})\n",
    "#     # print(leaves_pred_index_df)\n",
    "#     leaves_pred_index_dict = leaves_pred_index_df.groupby('leaves_pred').apply(lambda x: x.to_numpy()[:, -1]).to_dict()\n",
    "#     # print(leaves_pred_index_dict.items())\n",
    "#     for leaf, indices in leaves_pred_index_dict.items():\n",
    "#         np.random.seed(0)\n",
    "#         y_pred[indices] = np.random.choice(col_method.leaves_y_dict[leaf], size=len(indices), replace=True)\n",
    "    \n",
    "#     # map dtype to original dtype\n",
    "#     # synth_df[col] = synth_df[col].astype(mcce.df_dtypes[col])\n",
    "\n",
    "# synth_df = synth_df[test.columns]\n",
    "# print(synth_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = pd.read_csv(\"/nr/samba/user/anr/pkg/MCCE_Python/Results/give_me_some_credit_mcce_results_k_10000_n_100_inverse_transform.csv\", index_col=0)\n",
    "# temp.loc[263]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = OnlineCatalog(\"adult\")\n",
    "\n",
    "# results = pd.read_csv(f\"/nr/samba/user/anr/pkg/MCCE_Python/Results/adult_mcce_results_k_{K}_n_{n_test}.csv\")\n",
    "\n",
    "# dataset.inverse_transform(results.iloc[0:1])[['age', 'workclass', 'fnlwgt', 'education-num', 'marital-status', 'relationship', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_name = 'adult'\n",
    "# K = 50000\n",
    "# n_test = 100\n",
    "# import pandas as pd\n",
    "# results = pd.read_csv(f\"/nr/samba/user/anr/pkg/MCCE_Python/Results/{data_name}_mcce_results_k_{K}_n_{n_test}_inverse_transform.csv\")\n",
    "# print(results.L0.mean())\n",
    "# print(results.L1.mean())\n",
    "# print(results.L2.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(mcce.results_sparse.)\n",
    "# print(results.L0.mean())\n",
    "# print(results.L1.mean())\n",
    "# print(results.L2.mean())\n",
    "# print(results.feasibility.mean())\n",
    "# print(results.violation.mean())\n",
    "# print(results.success.mean())\n",
    "# print(results.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.read_csv(f\"/nr/samba/user/anr/pkg/MCCE_Python/Results/{data_name}_mcce_results_k_{K}_n_{n_test}.csv\")\n",
    "\n",
    "# results['data'] = data_name\n",
    "# results['method'] = 'mcce'\n",
    "# results.rename(columns={'violation': 'violations'}, inplace=True)\n",
    "\n",
    "# preds = ml_model.predict_proba(results)\n",
    "# new_preds = []\n",
    "# for x in preds:\n",
    "#     new_preds.append(x[1])\n",
    "# results['prediction'] = new_preds\n",
    "# results = dataset.inverse_transform(results)\n",
    "# results.head(1)\n",
    "\n",
    "# results['validity'] = np.where(np.asarray(new_preds) >= 0.5, 1, 0)\n",
    "\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# dataset = OnlineCatalog(\"give_me_some_credit\")\n",
    "\n",
    "# results = pd.read_csv(f\"/nr/samba/user/anr/pkg/MCCE_Python/give_me_some_credit_mcce_results_k_{K}_n_{n_test}.csv\")\n",
    "\n",
    "# results.rename(columns={'Unnamed: 0': 'index'}, inplace=True)\n",
    "# results.set_index(['index'], inplace=True)\n",
    "# temp = results.sort_values([results.index.name]).iloc[0:1]\n",
    "# dataset.inverse_transform(temp)[['age', 'RevolvingUtilizationOfUnsecuredLines', 'NumberOfTime30-59DaysPastDueNotWorse','DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mcce.results_sparse.)\n",
    "# print(mcce.results_sparse.L0.mean())\n",
    "# print(mcce.results_sparse.L1.mean())\n",
    "# print(mcce.results_sparse.L2.mean())\n",
    "# results_sparse = mcce.results_sparse\n",
    "# results_sparse.index.rename('index', inplace=True)\n",
    "# results_sparse.groupby('index').size().sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea38de303447ace9d448c28089670fa84711b12cac6767c435896f96584513e1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('carla_github')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
