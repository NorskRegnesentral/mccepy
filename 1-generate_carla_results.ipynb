{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for Tables 1, 2, 3 for CARLA methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carla.data.catalog import OnlineCatalog\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# load catalog dataset\n",
    "data_name = \"adult\"\n",
    "data_name = \"give_me_some_credit\"\n",
    "# data_name = 'compas'\n",
    "dataset = OnlineCatalog(data_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RevolvingUtilizationOfUnsecuredLines', 'age',\n",
       "       'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome',\n",
       "       'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate',\n",
       "       'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse',\n",
       "       'NumberOfDependents', 'SeriousDlqin2yrs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06787157980385537"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset.df[dataset.df.income==0].shape[0] / dataset.df.shape[0]\n",
    "dataset.df[dataset.df.SeriousDlqin2yrs==0].shape[0] / dataset.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carla.models.catalog import MLModelCatalog\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "ml_model = MLModelCatalog(\n",
    "        dataset, \n",
    "        model_type=\"ann\", \n",
    "        load_online=False, \n",
    "        backend=\"pytorch\"\n",
    "    )\n",
    "if data_name == 'adult':\n",
    "    ml_model.train(\n",
    "    learning_rate=0.002,\n",
    "    epochs=20,\n",
    "    batch_size=1024,\n",
    "    hidden_size=[18, 9, 3],\n",
    "    force_train=True, # don't forget to add this or it might load an older model from disk\n",
    "    )\n",
    "elif data_name == 'give_me_some_credit':\n",
    "    ml_model.train(\n",
    "    learning_rate=0.002,\n",
    "    epochs=20,\n",
    "    batch_size=2048,\n",
    "    hidden_size=[18, 9, 3],\n",
    "    force_train=True, # don't forget to add this or it might load an older model from disk\n",
    "    )\n",
    "elif data_name == 'compas':\n",
    "    ml_model.train(\n",
    "    learning_rate=0.002,\n",
    "    epochs=25,\n",
    "    batch_size=25,\n",
    "    hidden_size=[18, 9, 3],\n",
    "    force_train=True, # don't forget to add this or it might load an older model from disk\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "if data_name == 'adult':\n",
    "    y = dataset.df_test['income']\n",
    "elif data_name == 'give_me_some_credit':\n",
    "    y = dataset.df_test['SeriousDlqin2yrs']\n",
    "elif data_name == 'compas':\n",
    "    y = dataset.df_test['score']\n",
    "\n",
    "pred = ml_model.predict_proba(dataset.df_test)\n",
    "pred = [row[1] for row in pred]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=1)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carla.models.negative_instances import predict_negative_instances\n",
    "import carla.recourse_methods.catalog as recourse_catalog\n",
    "\n",
    "factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "test_factual = factuals.iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((f\"Factuals: {factuals.shape[0]}\"))\n",
    "print((f\"Factuals: {(factuals.shape[0]) / dataset.df.shape[0]}\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "results = []\n",
    "for method in ['cchvae', 'cem-vae', 'revise', 'clue', 'crud', 'face']:\n",
    "    if data_name == 'adult':\n",
    "        cfs = pd.read_csv(\"Results/adult_manifold_results.csv\")\n",
    "    elif data_name == 'give_me_some_credit':\n",
    "        cfs = pd.read_csv(\"Results/give_me_some_credit_manifold_results.csv\")\n",
    "    elif data_name == 'compas':\n",
    "        cfs = pd.read_csv(\"Results/compas_manifold_results.csv\")\n",
    "    factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "    test_factual = factuals.iloc[:100]\n",
    "\n",
    "    cfs.rename(columns={'Unnamed: 0': 'index'}, inplace=True)\n",
    "    cfs.set_index(['index'], inplace=True)\n",
    "\n",
    "    df_cfs = cfs[cfs['method'] == method].drop(['method',\t'data'], axis=1)\n",
    "\n",
    "    nan_idx = df_cfs.index[df_cfs.isnull().any(axis=1)]\n",
    "\n",
    "    output_factuals = test_factual.copy()\n",
    "    output_counterfactuals = df_cfs.copy()\n",
    "\n",
    "    output_factuals = output_factuals.drop(index=nan_idx)\n",
    "    output_counterfactuals = output_counterfactuals.drop(index=nan_idx)\n",
    "\n",
    "    test_factual = output_factuals\n",
    "    df_cfs = output_counterfactuals\n",
    "\n",
    "    df_decoded_cfs = dataset.inverse_transform(df_cfs.copy())\n",
    "\n",
    "    df_factuals = dataset.inverse_transform(test_factual.copy())\n",
    "\n",
    "    cfs_continuous_immutable = df_decoded_cfs[\n",
    "        intersection(dataset.continuous, dataset.immutables)\n",
    "    ]\n",
    "    factual_continuous_immutable = df_factuals[\n",
    "        intersection(dataset.continuous, dataset.immutables)\n",
    "    ]\n",
    "\n",
    "    continuous_violations = np.invert(\n",
    "        np.isclose(cfs_continuous_immutable, factual_continuous_immutable)\n",
    "    )\n",
    "    continuous_violations = np.sum(continuous_violations, axis=1).reshape(\n",
    "        (-1, 1)\n",
    "    )  # sum over features\n",
    "\n",
    "    # check categorical by boolean comparison\n",
    "    cfs_categorical_immutable = df_decoded_cfs[\n",
    "        intersection(dataset.categorical, dataset.immutables)\n",
    "    ]\n",
    "    factual_categorical_immutable = df_factuals[\n",
    "        intersection(dataset.categorical, dataset.immutables)\n",
    "    ]\n",
    "\n",
    "    categorical_violations = cfs_categorical_immutable != factual_categorical_immutable\n",
    "    categorical_violations = np.sum(categorical_violations.values, axis=1).reshape(\n",
    "        (-1, 1)\n",
    "    )  # sum over features\n",
    "\n",
    "    total_violations = continuous_violations + categorical_violations\n",
    "\n",
    "    for x in total_violations:\n",
    "        results.append(x[0])\n",
    "        \n",
    "final_results = cfs.copy()\n",
    "final_results.dropna(inplace=True)\n",
    "final_results['violations'] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "results = []\n",
    "for method in ['cchvae', 'cem-vae', 'revise', 'clue', 'crud', 'face']:\n",
    "    if data_name == 'adult':\n",
    "        cfs = pd.read_csv(\"Results/adult_manifold_results.csv\")\n",
    "    elif data_name == 'give_me_some_credit':\n",
    "        cfs = pd.read_csv(\"Results/give_me_some_credit_manifold_results.csv\")\n",
    "    elif data_name == 'compas':\n",
    "        cfs = pd.read_csv(\"Results/compas_manifold_results.csv\")\n",
    "    factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "    test_factual = factuals.iloc[:100]\n",
    "\n",
    "    cfs.rename(columns={'Unnamed: 0': 'index'}, inplace=True)\n",
    "    cfs.set_index(['index'], inplace=True)\n",
    "\n",
    "    df_cfs = cfs[cfs['method'] == method].drop(['method',\t'data'], axis=1)\n",
    "\n",
    "    nan_idx = df_cfs.index[df_cfs.isnull().any(axis=1)]\n",
    "\n",
    "    output_factuals = test_factual.copy()\n",
    "    output_counterfactuals = df_cfs.copy()\n",
    "\n",
    "    output_factuals = output_factuals.drop(index=nan_idx)\n",
    "    output_counterfactuals = output_counterfactuals.drop(index=nan_idx)\n",
    "\n",
    "    factual_without_nans = output_factuals\n",
    "    counterfactuals_without_nans = output_counterfactuals\n",
    "\n",
    "    columns = [\"Distance_1\", \"Distance_2\", \"Distance_3\", \"Distance_4\"]\n",
    "        \n",
    "    arr_f = ml_model.get_ordered_features(factual_without_nans).to_numpy()\n",
    "    arr_cf = ml_model.get_ordered_features(\n",
    "        counterfactuals_without_nans\n",
    "    ).to_numpy()\n",
    "\n",
    "    delta = arr_f - arr_cf \n",
    "\n",
    "    d1 = np.sum(np.invert(np.isclose(delta, np.zeros_like(delta))), axis=1, dtype=np.float).tolist()\n",
    "    d1_old = np.sum(delta.round(2) != 0, axis=1, dtype=np.float).tolist()\n",
    "\n",
    "    d2 = np.sum(np.abs(delta), axis=1, dtype=np.float).tolist()\n",
    "    d3 = np.sum(np.square(np.abs(delta)), axis=1, dtype=np.float).tolist()\n",
    "\n",
    "    results.append(pd.DataFrame({'L0': d1, 'L1': d2, 'L2': d3, 'time': df_cfs['time (seconds)'].mean()}))\n",
    "\n",
    "temp = pd.concat(results)\n",
    "temp.index = final_results.index\n",
    "final_results = pd.concat([final_results, temp], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for method in ['cchvae', 'cem-vae', 'revise', 'clue', 'crud', 'face']:\n",
    "    if data_name == 'adult':\n",
    "        cfs = pd.read_csv(\"Results/adult_manifold_results.csv\")\n",
    "        y_col = 'income'\n",
    "    elif data_name == 'give_me_some_credit':\n",
    "        cfs = pd.read_csv(\"Results/give_me_some_credit_manifold_results.csv\")\n",
    "        y_col = \"SeriousDlqin2yrs\"\n",
    "    elif data_name == 'compas':\n",
    "        cfs = pd.read_csv(\"Results/compas_manifold_results.csv\")\n",
    "        y_col = \"score\"\n",
    "\n",
    "    cfs.rename(columns={'Unnamed: 0': 'index'}, inplace=True)\n",
    "    cfs.set_index(['index'], inplace=True)\n",
    "\n",
    "    df_cfs = cfs[cfs['method'] == method].drop(['method',\t'data'], axis=1)\n",
    "    results.append(pd.DataFrame({'validity': df_cfs[y_col]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ml_model.predict_proba(final_results)\n",
    "temp2 = []\n",
    "temp3 = []\n",
    "for x in temp:\n",
    "    temp2.append(x[1]>= 0.5) #  >= 0.5\n",
    "\n",
    "    temp3.append(x[1]) #  >= 0.5\n",
    "    \n",
    "final_results['validity'] = temp2\n",
    "final_results['prediction'] = temp3\n",
    "final_results['validity'] = final_results['validity'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feasibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "results = []\n",
    "for method in ['cchvae', 'cem-vae', 'revise', 'clue', 'crud', 'face']:\n",
    "    if data_name == 'adult':\n",
    "        cfs = pd.read_csv(\"Results/adult_manifold_results.csv\")\n",
    "    elif data_name == 'give_me_some_credit':\n",
    "        cfs = pd.read_csv(\"Results/give_me_some_credit_manifold_results.csv\")\n",
    "    elif data_name == 'compas':\n",
    "        cfs = pd.read_csv(\"Results/compas_manifold_results.csv\")\n",
    "    factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "    test_factual = factuals.iloc[:100]\n",
    "\n",
    "    cfs.rename(columns={'Unnamed: 0': 'index'}, inplace=True)\n",
    "    cfs.set_index(['index'], inplace=True)\n",
    "\n",
    "    df_cfs = cfs[cfs['method'] == method].drop(['method',\t'data'], axis=1)\n",
    "\n",
    "    nan_idx = df_cfs.index[df_cfs.isnull().any(axis=1)]\n",
    "\n",
    "    output_factuals = test_factual.copy()\n",
    "    output_counterfactuals = df_cfs.copy()\n",
    "\n",
    "    output_factuals = output_factuals.drop(index=nan_idx)\n",
    "    output_counterfactuals = output_counterfactuals.drop(index=nan_idx)\n",
    "\n",
    "    factual_without_nans = output_factuals\n",
    "    counterfactuals_without_nans = output_counterfactuals\n",
    "\n",
    "\n",
    "    cols = dataset.df.columns\n",
    "    cols.drop(dataset.target)\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=5).fit(factual_without_nans[cols].values)\n",
    "\n",
    "    for i, row in counterfactuals_without_nans[cols].iterrows():\n",
    "        knn = nbrs.kneighbors(row.values.reshape((1, -1)), 5, return_distance=True)[0]\n",
    "        \n",
    "        results.append(np.mean(knn))\n",
    "final_results['feasibility'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "temp = final_results[['L0', 'L1', 'L2',  'feasibility', 'violations', 'validity', 'prediction']]\n",
    "cfs.dropna(inplace=True)\n",
    "temp = pd.concat([temp, dataset.inverse_transform(cfs)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv(f\"/nr/samba/user/anr/pkg/MCCE_Python/Results/{data_name}_mcce_results_k_10000_n_100.csv\", index_col=0)\n",
    "\n",
    "results['data'] = data_name\n",
    "results['method'] = 'mcce'\n",
    "results.rename(columns={'violation': 'violations'}, inplace=True)\n",
    "\n",
    "preds = ml_model.predict_proba(results)\n",
    "new_preds = []\n",
    "for x in preds:\n",
    "    new_preds.append(x[1])\n",
    "results['prediction'] = new_preds\n",
    "results = dataset.inverse_transform(results)\n",
    "results.head(1)\n",
    "\n",
    "results['validity'] = np.where(np.asarray(new_preds) >= 0.5, 1, 0)\n",
    "\n",
    "# results.loc[263]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([temp, results[temp.columns]])\n",
    "\n",
    "temp2 = factuals.copy()\n",
    "preds = ml_model.predict_proba(temp2)\n",
    "new_preds = []\n",
    "for x in preds:\n",
    "    new_preds.append(x[1])\n",
    "temp2['prediction'] = new_preds\n",
    "temp2 = dataset.inverse_transform(temp2)\n",
    "temp2.head(1)\n",
    "temp2['L0'] = np.nan\n",
    "temp2['L1'] = np.nan\n",
    "temp2['L2'] = np.nan\n",
    "temp2['validity'] = np.nan\n",
    "temp2['violations'] = np.nan\n",
    "temp2['feasibility'] = np.nan\n",
    "temp2['time (seconds)'] = np.nan\n",
    "temp2['method'] = 'original'\n",
    "temp2['data'] = data_name\n",
    "\n",
    "temp = pd.concat([temp, temp2.iloc[0:100][temp.columns]], axis=0)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.read_csv(f\"/nr/samba/user/anr/pkg/MCCE_Python/Results/{data_name}_baseline_results_n_100.csv\", index_col=0)\n",
    "# results['data'] = data_name\n",
    "# results['method'] = 'baseline'\n",
    "# results.rename(columns={'violation': 'violations'}, inplace=True)\n",
    "\n",
    "# preds = ml_model.predict_proba(results)\n",
    "# new_preds = []\n",
    "# for x in preds:\n",
    "#     new_preds.append(x[1])\n",
    "# results['prediction'] = new_preds\n",
    "# results = dataset.inverse_transform(results)\n",
    "# results.head(1)\n",
    "\n",
    "# results['validity'] = np.where(np.asarray(new_preds) >= 0.5, 1, 0)\n",
    "# results[temp.columns]\n",
    "# temp = pd.concat([temp, results[temp.columns]])\n",
    "# temp\n",
    "\n",
    "# temp.columns[9:13].to_list() + temp.columns[15:].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_name == 'give_me_some_credit':\n",
    "    cols = ['method', 'data', 'prediction', 'L0', 'L1', 'L2', 'feasibility', 'violations', 'validity', 'time (seconds)'] + temp.columns[9:-1].to_list()\n",
    "    temp = temp[cols]\n",
    "elif data_name == 'adult':\n",
    "    cols = ['method', 'data', 'prediction', 'L0', 'L1', 'L2', 'feasibility', 'violations', 'validity', 'time (seconds)'] + temp.columns[9:16].to_list() + temp.columns[17:].to_list()\n",
    "    temp = temp[cols]\n",
    "\n",
    "elif data_name == 'compas':\n",
    "    cols = ['method', 'data', 'prediction', 'L0', 'L1', 'L2', 'feasibility', 'violations', 'validity', 'time (seconds)'] + temp.columns[9:13].to_list() + temp.columns[15:].to_list()\n",
    "    temp = temp[cols]\n",
    "temp.to_csv(f\"Final_results/{data_name}_results_mcce_and_carla_K_10000_n_100.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To get Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"Final_results/adult_results_mcce_and_carla_K_10000_n_100.csv\", index_col=0)\n",
    "\n",
    "to_write = temp[['method', 'L0', 'L2', 'feasibility', 'violations', 'validity', 'time (seconds)']].groupby(['method']).mean()\n",
    "\n",
    "to_write.reset_index(inplace=True)\n",
    "\n",
    "CE_N = temp.groupby(['method']).size().reset_index().rename(columns={0: 'CE_N'})\n",
    "to_write = pd.concat([to_write, CE_N.CE_N], axis=1)\n",
    "\n",
    "# to_write.sort_values(['method'], inplace=True, ascending=False)\n",
    "to_write = to_write[['method', 'L0', 'L2', 'feasibility', 'violations', 'validity', 'CE_N', 'time (seconds)']]\n",
    "\n",
    "print(to_write.to_latex(index=False, float_format=\"%.2f\", ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"Final_results/give_me_some_credit_results_mcce_and_carla_K_10000_n_100.csv\", index_col=0)\n",
    "\n",
    "to_write = temp[['method', 'L0', 'L2', 'feasibility', 'violations', 'validity', 'time (seconds)']].groupby(['method']).mean()\n",
    "\n",
    "to_write.reset_index(inplace=True)\n",
    "\n",
    "CE_N = temp.groupby(['method']).size().reset_index().rename(columns={0: 'CE_N'})\n",
    "to_write = pd.concat([to_write, CE_N.CE_N], axis=1)\n",
    "\n",
    "# to_write.sort_values(['method'], inplace=True, ascending=False)\n",
    "to_write = to_write[['method', 'L0', 'L2', 'feasibility', 'violations', 'validity', 'CE_N', 'time (seconds)']]\n",
    "\n",
    "print(to_write.to_latex(index=False, float_format=\"%.2f\", ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"Final_results/compas_results_mcce_and_carla_K_10000_n_100.csv\", index_col=0)\n",
    "\n",
    "to_write = temp[['method', 'L0', 'L2', 'feasibility', 'violations', 'validity', 'time (seconds)']].groupby(['method']).mean()\n",
    "\n",
    "to_write.reset_index(inplace=True)\n",
    "\n",
    "CE_N = temp.groupby(['method']).size().reset_index().rename(columns={0: 'CE_N'})\n",
    "to_write = pd.concat([to_write, CE_N.CE_N], axis=1)\n",
    "\n",
    "# to_write.sort_values(['method'], inplace=True, ascending=False)\n",
    "to_write = to_write[['method', 'L0', 'L2', 'feasibility', 'violations', 'validity', 'CE_N', 'time (seconds)']]\n",
    "\n",
    "print(to_write.to_latex(index=False, float_format=\"%.2f\", ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To get Adult examples in table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "temp = pd.read_csv(\"Final_results/adult_results_mcce_and_carla_K_10000_n_100.csv\", index_col=0)\n",
    "\n",
    "# cols = ['Method', 'Pred', 'Age', 'Work Class', 'FNLWGT', 'Educat.', 'Mar. Stat.', 'Relat.', 'Cap. Gain', 'Cap. Loss', 'Hr.', 'Co.']\n",
    "\n",
    "# cols = ['method', 'prediction', 'age', 'workclass', 'fnlwgt', 'education-num', 'marital-status', 'relationship', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
    "\n",
    "to_write = temp.loc[31]\n",
    "# to_write.columns = cols\n",
    "# to_write.sort_values(['Method'], inplace=True, ascending=False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "to_write\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(to_write.Pred.to_latex(index=False, float_format=\"%.2f\", ))\n",
    "feature = 'marital-status'\n",
    "dct = {'Married': 'M', 'Non-Married': 'NM'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "feature = 'native-country'\n",
    "dct = {'Non-US': 'NUS', 'US': 'US'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "feature = 'occupation'\n",
    "dct = {'Managerial-Specialist': 'MS', 'Other': 'O'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "feature = 'race'\n",
    "dct = {'White': 'W', 'Non-White': 'NW'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "feature = 'relationship'\n",
    "dct = {'Husband': 'H', 'Non-Husband': 'NH'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "feature = 'sex'\n",
    "dct = {'Male': 'M'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "\n",
    "feature = 'workclass'\n",
    "dct = {'Self-emp-not-inc': 'SENI', 'Private': 'P', 'Non-Private': 'NP'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['method', 'age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', \\\n",
    "       'hours-per-week', 'marital-status', 'native-country', \\\n",
    "       'occupation', 'race', 'relationship', 'sex', 'workclass']\n",
    "\n",
    "print(to_write[cols].to_latex(index=False, float_format=\"%.0f\", ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To get GMC examples in table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"Final_results/give_me_some_credit_results_mcce_and_carla_K_10000_n_100.csv\", index_col=0)\n",
    "# temp.loc[263]\n",
    "\n",
    "cols = ['method', 'prediction', 'age', 'RevolvingUtilizationOfUnsecuredLines', 'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']\n",
    "\n",
    "to_write = temp[cols].loc[263]\n",
    "\n",
    "cols = ['Method', 'Pred', 'Age', 'Unsec. Lines', 'Nb Days Past 30', 'Debt Ratio', 'Month Inc.', 'Nb Credit Lines', 'Nb Times 90 Days Late', 'Nb Real Estate Loans', 'Nb Times 60 Days Past', 'Nb Dep.']\n",
    "\n",
    "to_write.columns = cols\n",
    "# to_write.sort_values(['Method'], inplace=True, ascending=False)\n",
    "\n",
    "# print(to_write.to_latex(index=False, float_format=\"%.0f\", ))\n",
    "\n",
    "print(to_write.to_latex(index=False, float_format=\"%.2f\", ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_name == 'give_me_some_credit':\n",
    "    features = [ 'age', 'RevolvingUtilizationOfUnsecuredLines', 'NumberOfTime30-59DaysPastDueNotWorse','DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']\n",
    "    metric_names = ['method', 'L0', 'L1', 'violations', 'validity', 'prediction']\n",
    "\n",
    "    temp = dataset.inverse_transform(final_results.dropna()[features])\n",
    "    temp = pd.concat([final_results[metric_names], temp], axis=1)\n",
    "    # temp.sort_values(temp.index.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_name == 'give_me_some_credit':\n",
    "    mcce_results = pd.read_csv(f\"/nr/samba/user/anr/pkg/MCCE_Python/give_me_some_credit_mcce_results_k_10000.csv\")\n",
    "    mcce_results.rename(columns={'Unnamed: 0': 'index'}, inplace=True)\n",
    "    mcce_results.set_index(['index'], inplace=True)\n",
    "\n",
    "    predictions = ml_model.predict_proba(mcce_results)\n",
    "    temp3 = []\n",
    "    for x in predictions:\n",
    "        temp3.append(x[1]) #  >= 0.5\n",
    "        \n",
    "    # temp.index = final_results.index\n",
    "    mcce_results['prediction'] = temp3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_name == 'give_me_some_credit':\n",
    "    mcce_results.sort_values(mcce_results.index.name, inplace=True)\n",
    "    mcce_results['method'] = 'mcce'\n",
    "    mcce_results.rename(columns={'success': 'validity', 'violation': 'violations'}, inplace=True)\n",
    "    temp_mcce = dataset.inverse_transform(mcce_results.dropna()[features])\n",
    "    temp_mcce = pd.concat([mcce_results[metric_names], temp_mcce], axis=1)\n",
    "    # temp_mcce.sort_values(temp_mcce.index.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_name == 'give_me_some_credit':\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    temp2 = pd.concat([temp, temp_mcce], axis=0)\n",
    "\n",
    "    temp2.sort_values(temp2.index.name)\n",
    "\n",
    "    features = ['method', 'prediction', 'age', 'RevolvingUtilizationOfUnsecuredLines', 'NumberOfTime30-59DaysPastDueNotWorse','DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']\n",
    "\n",
    "    temp2.loc[263][features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_name == 'give_me_some_credit':\n",
    "    factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "    dataset.inverse_transform(factuals.iloc[3:4])[['age', 'RevolvingUtilizationOfUnsecuredLines', 'NumberOfTime30-59DaysPastDueNotWorse','DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']]\n",
    "\n",
    "    ml_model.predict_proba(factuals.iloc[3:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"Final_results/compas_results_mcce_and_carla_K_10000_n_100.csv\", index_col=0)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = ['method', 'prediction', 'age', 'two_year_recid', 'priors_count', 'length_of_stay', 'c_charge_degree', 'race', 'sex']\n",
    "\n",
    "to_write = temp[cols].loc[40]\n",
    "\n",
    "cols = ['Method', 'Pred', 'Age', 'Two Year Recid', 'Priors Count', 'Length of Stay', 'C Charge Degree', 'Race', 'Sex']\n",
    "\n",
    "to_write.columns = cols\n",
    "# to_write.sort_values(['Method'], inplace=True, ascending=False)\n",
    "\n",
    "# print(to_write.to_latex(index=False, float_format=\"%.0f\", ))\n",
    "\n",
    "print(to_write.to_latex(index=False, float_format=\"%.2f\", ))\n",
    "\n",
    "round(to_write[['Method', 'Pred']],2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea38de303447ace9d448c28089670fa84711b12cac6767c435896f96584513e1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('carla_github')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
