{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from carla.data.catalog import OnlineCatalog\n",
    "from carla.models.negative_instances import predict_negative_instances\n",
    "\n",
    "from mcce import MCCE\n",
    "\n",
    "data_name = \"adult\"\n",
    "data_name = 'give_me_some_credit'\n",
    "data_name = 'compas'\n",
    "K = 10000\n",
    "n_test = 100\n",
    "results_all = None\n",
    "\n",
    "dataset = OnlineCatalog(data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carla import MLModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class RandomForestModel(MLModel):\n",
    "    \"\"\"The default way of implementing RandomForest from sklearn\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        super().__init__(data)\n",
    "\n",
    "        # get preprocessed data\n",
    "        df_train = self.data.df_train\n",
    "        df_test = self.data.df_test\n",
    "        \n",
    "        encoded_features = list(self.data.encoder.get_feature_names(self.data.categorical))\n",
    "        \n",
    "        x_train = df_train[self.data.continuous + encoded_features]\n",
    "        y_train = df_train[self.data.target]\n",
    "        x_test = df_test[self.data.continuous + encoded_features]\n",
    "        y_test = df_test[self.data.target]\n",
    "\n",
    "        # print(x_train)\n",
    "\n",
    "        self._feature_input_order = self.data.continuous + encoded_features\n",
    "\n",
    "        param = {\n",
    "            \"max_depth\": None,  # determines how deep the tree can go\n",
    "            \"n_estimators\": 200,\n",
    "            \"min_samples_split\": 3 # number of features to consider at each split\n",
    "        }\n",
    "        self._mymodel = RandomForestClassifier(**param)\n",
    "        self._mymodel.fit(\n",
    "                x_train,\n",
    "                y_train,\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def feature_input_order(self):\n",
    "        # List of the feature order the ml model was trained on\n",
    "        return self._feature_input_order\n",
    "\n",
    "    @property\n",
    "    def backend(self):\n",
    "        # The ML framework the model was trained on\n",
    "        return \"xgboost\"\n",
    "\n",
    "    @property\n",
    "    def raw_model(self):\n",
    "        # The black-box model object\n",
    "        return self._mymodel\n",
    "\n",
    "    @property\n",
    "    def tree_iterator(self):\n",
    "        # make a copy of the trees, else feature names are not saved\n",
    "        booster_it = [booster for booster in self.raw_model.get_booster()]\n",
    "        # set the feature names\n",
    "        for booster in booster_it:\n",
    "            booster.feature_names = self.feature_input_order\n",
    "        return booster_it\n",
    "\n",
    "    # The predict function outputs\n",
    "    # the continuous prediction of the model\n",
    "    def predict(self, x):\n",
    "        return self._mymodel.predict(self.get_ordered_features(x))\n",
    "\n",
    "    # The predict_proba method outputs\n",
    "    # the prediction as class probabilities\n",
    "    def predict_proba(self, x):\n",
    "        # print(self.get_ordered_features(x))\n",
    "        return self._mymodel.predict_proba(self.get_ordered_features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_model = RandomForestModel(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8342733412882819"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "pred = ml_model.predict_proba(dataset.df_test)\n",
    "pred = [row[1] for row in pred]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(dataset.df_test[dataset.target], pred, pos_label=1)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "test_factual = factuals.iloc[:n_test]\n",
    "\n",
    "y_col = dataset.target\n",
    "features_and_response = dataset.df.columns\n",
    "cont_feat = dataset.continuous\n",
    "cat_feat = [x for x in features_and_response if x not in cont_feat] #  these have new names since encode_normalize_order_factuals()\n",
    "\n",
    "if data_name == 'adult': \n",
    "    fixed_features = ['age', 'sex_Male']\n",
    "elif data_name == 'give_me_some_credit':\n",
    "    fixed_features = ['age']\n",
    "elif data_name == 'compas':\n",
    "    fixed_features = ['age', 'sex_Male', 'race_Other']\n",
    "\n",
    "#  Create dtypes for MCCE()\n",
    "dtypes = dict([(x, \"float\") for x in cont_feat])\n",
    "for x in cat_feat:\n",
    "    dtypes[x] = \"category\"\n",
    "df = (dataset.df).astype(dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# (3) Fit MCCE object\n",
    "print(\"Fitting MCCE model...\")\n",
    "mcce = MCCE(fixed_features=fixed_features, immutables=['age', 'sex'], model=ml_model, seed=1, continuous=dataset.continuous, categorical=dataset.categorical)\n",
    "mcce.fit(df.drop(y_col, axis=1), dtypes)\n",
    "\n",
    "print(\"Generating counterfactuals with MCCE...\")\n",
    "synth_df = mcce.generate(test_factual.drop(y_col, axis=1), k=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcce.postprocess(data=df, synth=synth_df, test=test_factual, \\\n",
    "    response=y_col, inverse_transform=dataset.inverse_transform, cutoff=0.5)\n",
    "\n",
    "timing = time.time() - start\n",
    "print(timing)\n",
    "\n",
    "mcce.results_sparse['time (seconds)'] = timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# data=df\n",
    "# synth=synth_df\n",
    "# test=test_factual\n",
    "# response=y_col\n",
    "# inverse_transform=dataset.inverse_transform\n",
    "# cutoff=0.5\n",
    "# # Predict response of generated data\n",
    "# synth[response] = ml_model.predict(synth)\n",
    "# synth_positive = synth[synth[response]>=cutoff] # drop negative responses\n",
    "\n",
    "\n",
    "# # Duplicate original test observations N times where N is number of positive counterfactuals\n",
    "# n_counterfactuals = synth_positive.groupby(synth_positive.index).size()\n",
    "# n_counterfactuals = pd.DataFrame(n_counterfactuals, columns = ['N'])\n",
    "\n",
    "# test_repeated = test.copy()\n",
    "\n",
    "# test_repeated = test_repeated.join(n_counterfactuals)\n",
    "# test_repeated.dropna(inplace = True)\n",
    "\n",
    "# test_repeated = test_repeated.reindex(test_repeated.index.repeat(test_repeated.N))\n",
    "# test_repeated.drop(['N'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# synth=synth_positive\n",
    "# test=test_repeated\n",
    "\n",
    "# features = synth.columns.to_list()\n",
    "# features.remove(response)\n",
    "\n",
    "# synth_metrics = synth.copy()\n",
    "\n",
    "# synth.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "# # 1) Distance: Sparsity and Euclidean distance\n",
    "# factual = test[features].sort_index().to_numpy()\n",
    "# counterfactuals = synth[features].sort_index().to_numpy()\n",
    "\n",
    "# delta = factual - counterfactuals # get_delta(factual, counterfactuals)\n",
    "\n",
    "# d1 = np.sum(delta != 0, axis=1, dtype=float).tolist() # sparsity\n",
    "# d2 = np.sum(np.abs(delta), axis=1, dtype=float).tolist() # manhatten distance\n",
    "# d3 = np.sum(np.square(np.abs(delta)), axis=1, dtype=np.float).tolist() # euclidean distance\n",
    "\n",
    "# synth_metrics['L0'] = d1\n",
    "# synth_metrics['L1'] = d2\n",
    "# synth_metrics['L2'] = d3\n",
    "\n",
    "# # 3) kNN\n",
    "# # neighb = yNN(data, synth, response, y=5)\n",
    "# # synth_metrics['yNN'] = neighb\n",
    "\n",
    "\n",
    "# # 4) Feasibility \n",
    "# # feas = feasibility(data, synth, response, y=5)\n",
    "# # synth_metrics['feasibility'] = feas\n",
    "\n",
    "# cols = data.columns\n",
    "# cols.drop(response)\n",
    "\n",
    "# feas_results = []\n",
    "# nbrs = NearestNeighbors(n_neighbors=5).fit(synth[cols].values)\n",
    "\n",
    "# for i, row in synth[cols].iterrows():\n",
    "#     knn = nbrs.kneighbors(row.values.reshape((1, -1)), 5, return_distance=True)[0]\n",
    "    \n",
    "#     feas_results.append(np.mean(knn))\n",
    "\n",
    "# synth_metrics['feasibility'] = feas_results\n",
    "\n",
    "# # 5) Redundancy \n",
    "# # redund = redundancy(synth, test, model, response)\n",
    "# # synth_metrics['redundancy'] = redund\n",
    "\n",
    "# # 6) Success\n",
    "# synth_metrics['success'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synth.sort_index(inplace=True)\n",
    "\n",
    "# def intersection(lst1, lst2):\n",
    "#     return list(set(lst1) & set(lst2))\n",
    "\n",
    "# df_decoded_cfs = inverse_transform(synth.copy())\n",
    "\n",
    "# df_factuals = inverse_transform(test.copy())\n",
    "\n",
    "# # check continuous using np.isclose to allow for very small numerical differences\n",
    "# cfs_continuous_immutable = df_decoded_cfs[\n",
    "#     intersection(dataset.continuous, fixed_features)\n",
    "# ]\n",
    "# # print(self.continuous)\n",
    "# # print(self.immutables)\n",
    "# # print(self.categorical)\n",
    "# factual_continuous_immutable = df_factuals[\n",
    "#     intersection(dataset.continuous, dataset.immutables)\n",
    "# ]\n",
    "\n",
    "# continuous_violations = np.invert(\n",
    "#     np.isclose(cfs_continuous_immutable, factual_continuous_immutable)\n",
    "# )\n",
    "# continuous_violations = np.sum(continuous_violations, axis=1).reshape(\n",
    "#     (-1, 1)\n",
    "# )  # sum over features\n",
    "\n",
    "# # print(continuous_violations)\n",
    "\n",
    "# # check categorical by boolean comparison\n",
    "# cfs_categorical_immutable = df_decoded_cfs[\n",
    "#     intersection(dataset.categorical, dataset.immutables)\n",
    "# ]\n",
    "# # print(cfs_categorical_immutable)\n",
    "# factual_categorical_immutable = df_factuals[\n",
    "#     intersection(dataset.categorical, dataset.immutables)\n",
    "# ]\n",
    "\n",
    "\n",
    "# cfs_categorical_immutable.sort_index(inplace=True)\n",
    "# factual_categorical_immutable.sort_index(inplace=True)\n",
    "# cfs_categorical_immutable.index.name = None\n",
    "\n",
    "# categorical_violations = cfs_categorical_immutable != factual_categorical_immutable\n",
    "# categorical_violations = np.sum(categorical_violations.values, axis=1).reshape(\n",
    "#     (-1, 1)\n",
    "# )  # sum over features\n",
    "\n",
    "# synth_metrics['violation'] = continuous_violations + categorical_violations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcce.results_sparse.to_csv(f\"/nr/samba/user/anr/pkg/MCCE_Python/Results/{data_name}_mcce_results_tree_model_k_{K}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "# K = 10000\n",
    "# mcce_results = pd.read_csv(f\"/nr/samba/user/anr/pkg/MCCE_Python/Results/adult_mcce_results_tree_model_k_{K}.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_preds = ml_model.predict_proba(test_factual)\n",
    "# new_preds = []\n",
    "# for x in orig_preds:\n",
    "#     new_preds.append(x[1])\n",
    "\n",
    "# test_inverse = dataset.inverse_transform(test_factual)\n",
    "# test_inverse['pred'] = new_preds\n",
    "# test_inverse[['age', 'workclass', 'fnlwgt', 'education-num', 'marital-status', 'relationship', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'give_me_some_credit'\n",
    "data_name = 'compas'\n",
    "test_inverse = pd.read_csv(f\"/nr/samba/user/anr/pkg/MCCE_Python/Results/{data_name}_tree_model_n_100_inverse_transform.csv\", index_col=0)\n",
    "test_inverse['method'] = 'MCCE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.27\n",
      "0.047482883353531846\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "100\n",
      "2654.794924974441\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "results_inverse = pd.read_csv(f\"/nr/samba/user/anr/pkg/MCCE_Python/Results/{data_name}_mcce_results_tree_model_k_10000_n_100_inverse_transform.csv\", index_col=0)\n",
    "results_inverse['method'] = 'Original'\n",
    "\n",
    "print(results_inverse.L0.mean())\n",
    "print(results_inverse.L2.mean())\n",
    "print(results_inverse.feasibility.mean())\n",
    "print(results_inverse.violation.mean())\n",
    "print(results_inverse.success.mean())\n",
    "print(results_inverse.shape[0])\n",
    "print(results_inverse['time (seconds)'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RevolvingUtilizationOfUnsecuredLines', 'age',\n",
       "       'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome',\n",
       "       'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate',\n",
       "       'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse',\n",
       "       'NumberOfDependents', 'SeriousDlqin2yrs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.concat([test_inverse, results_inverse])\n",
    "temp.index.to_list()[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if data_name == 'adult':\n",
    "       cols = ['method', 'age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', \\\n",
    "              'hours-per-week', 'marital-status', 'native-country', \\\n",
    "              'occupation', 'race', 'relationship', 'sex', 'workclass']\n",
    "       \n",
    "       to_write = temp[cols].loc[[1, 31, 122, 124]].sort_index()\n",
    "       to_write.columns = cols\n",
    "\n",
    "elif data_name == 'give_me_some_credit':\n",
    "       cols = ['method', 'age', 'RevolvingUtilizationOfUnsecuredLines', \\\n",
    "       'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome', \\\n",
    "       'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', \\\n",
    "       'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', \\\n",
    "       'NumberOfDependents']\n",
    "\n",
    "       to_write = temp[cols].loc[[287, 512, 1013, 1612]].sort_index()\n",
    "\n",
    "       cols = ['method', 'Age', 'Unsec. Lines', \\\n",
    "       '30 Days Past', 'Debt Ratio', 'Month Inc', \\\n",
    "       'Credit Lines', '90 Days Late', \\\n",
    "       'Real Est. Loans', '60 Days Past', \\\n",
    "       'Nb Dep.']\n",
    "\n",
    "\n",
    "       to_write.columns = cols\n",
    "\n",
    "elif data_name == 'compas':\n",
    "       cols = ['method', 'age', 'two_year_recid', 'priors_count', 'length_of_stay',\n",
    "       'c_charge_degree', 'race', 'sex']\n",
    "\n",
    "       to_write = temp[cols].loc[[67, 286]].sort_index()\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_name == 'adult':\n",
    "    feature = 'marital-status'\n",
    "    dct = {'Married': 'M', 'Non-Married': 'NM'}\n",
    "    to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "    feature = 'native-country'\n",
    "    dct = {'Non-US': 'NUS', 'US': 'US'}\n",
    "    to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "    feature = 'occupation'\n",
    "    dct = {'Managerial-Specialist': 'MS', 'Other': 'O'}\n",
    "    to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "    feature = 'race'\n",
    "    dct = {'White': 'W', 'Non-White': 'NW'}\n",
    "    to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "\n",
    "    feature = 'relationship'\n",
    "    dct = {'Husband': 'H', 'Non-Husband': 'NH'}\n",
    "    to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "    feature = 'sex'\n",
    "    dct = {'Male': 'M'}\n",
    "    to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "\n",
    "    feature = 'workclass'\n",
    "    dct = {'Self-emp-not-inc': 'SENI', 'Private': 'P', 'Non-Private': 'NP'}\n",
    "    to_write[feature] = [dct[item] for item in to_write[feature]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrlll}\n",
      "\\toprule\n",
      "   method &  age &  two\\_year\\_recid &  priors\\_count &  length\\_of\\_stay & c\\_charge\\_degree &              race &   sex \\\\\n",
      "\\midrule\n",
      "     MCCE &   22 &               0 &             0 &              57 &               F &             Other &  Male \\\\\n",
      " Original &   22 &               0 &             0 &               7 &               F &             Other &  Male \\\\\n",
      "     MCCE &   32 &               1 &            12 &               1 &               F &  African-American &  Male \\\\\n",
      " Original &   32 &               1 &             4 &               1 &               F &  African-American &  Male \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(to_write.to_latex(index=False, float_format=\"%.0f\", ))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea38de303447ace9d448c28089670fa84711b12cac6767c435896f96584513e1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('carla_github')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
