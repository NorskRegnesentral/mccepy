{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from mcce import MCCE\n",
    "n_test = 100\n",
    "K = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw train/test of Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"Data/adult.data\"\n",
    "test_path = \"Data/adult.test\"\n",
    "train = pd.read_csv(train_path, sep=\", \", header=None, \\\n",
    "    names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', \\\n",
    "        'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'])\n",
    "test = pd.read_csv(test_path, skiprows=1, sep=\", \", header=None, \\\n",
    "    names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', \\\n",
    "        'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'])\n",
    "\n",
    "df = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "df = df.drop(['education'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess categorical features to have 4 levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\">50K\": \">50K\", \">50K.\": \">50K\", \"<=50K\": \"<=50K\", \"<=50K.\": \"<=50K\"}\n",
    "\n",
    "df[\"income\"] = [mapping[item] for item in df[\"income\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in [\"workclass\", \"marital-status\", \"occupation\", \"relationship\", \\\n",
    "    \"sex\", \"race\", \"native-country\", \"income\"]:\n",
    "    d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "    for i, ind in enumerate(d):\n",
    "        if i <= 3:\n",
    "            d[i] = i\n",
    "        else:\n",
    "            d[i] = 3\n",
    "    mapping = d.to_dict()\n",
    "    df[feature] = [mapping[item] for item in df[feature]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Data/train_not_normalized_data_from_carla.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data in using CARLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carla.data.catalog import CsvCatalog\n",
    "\n",
    "continuous = [\"age\", \"fnlwgt\", \"education-num\", \"capital-gain\", \"hours-per-week\", \"capital-loss\"]\n",
    "categorical = [\"marital-status\", \"native-country\", \"occupation\", \"race\", \"relationship\", \"sex\", \"workclass\"]\n",
    "immutable = [\"age\", \"sex\"]\n",
    "\n",
    "dataset = CsvCatalog(file_path=\"Data/train_not_normalized_data_from_carla.csv\",\n",
    "                     continuous=continuous,\n",
    "                     categorical=categorical,\n",
    "                     immutables=immutable,\n",
    "                     target=\"income\",\n",
    "                     encoding_method=\"OneHot_drop_first\", # This is important for non-binarized data\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.catalog = {'target': dataset.target, 'continuous': dataset.continuous, 'categorical': dataset.categorical, 'immutable': dataset.immutables}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carla.models.catalog import MLModelCatalog\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "ml_model = MLModelCatalog(\n",
    "        dataset, \n",
    "        model_type=\"ann\", \n",
    "        load_online=False, \n",
    "        backend=\"pytorch\"\n",
    "    )\n",
    "\n",
    "ml_model.train(\n",
    "learning_rate=0.002,\n",
    "epochs=20,\n",
    "batch_size=1024,\n",
    "hidden_size=[18, 9, 3],\n",
    "force_train=True, # don't forget to add this or it might load an older model from disk\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "pred = ml_model.predict_proba(dataset.df_test)\n",
    "pred = [row[1] for row in pred]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(dataset.df_test[dataset.target], pred, pos_label=1)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for MCCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carla.models.negative_instances import predict_negative_instances\n",
    "\n",
    "factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "test_factual = factuals.iloc[:n_test]\n",
    "\n",
    "y_col = dataset.target\n",
    "cont_feat = dataset.continuous\n",
    "\n",
    "cat_feat = dataset.categorical\n",
    "cat_feat_encoded = dataset.encoder.get_feature_names(dataset.categorical)\n",
    "\n",
    "fixed_features_encoded = ['age', 'sex_1']\n",
    "fixed_features = ['age', 'sex']\n",
    "\n",
    "#  Create dtypes for MCCE()\n",
    "dtypes = dict([(x, \"float\") for x in cont_feat])\n",
    "for x in cat_feat_encoded:\n",
    "    dtypes[x] = \"category\"\n",
    "df = (dataset.df).astype(dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit MCCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcce = MCCE(fixed_features=fixed_features,\\\n",
    "#     fixed_features_encoded=fixed_features_encoded,\n",
    "#         continuous=dataset.continuous, categorical=dataset.categorical,\\\n",
    "#             model=ml_model, seed=1)\n",
    "\n",
    "# mcce.fit(df.drop(dataset.target, axis=1), dtypes)\n",
    "\n",
    "# synth_df = mcce.generate(test_factual.drop(dataset.target, axis=1), k=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "K = 100\n",
    "n_test = 10\n",
    "results_inverse = pd.read_csv(f\"Results/adult_mcce_results_raw_data_k_{K}_n_{n_test}_inverse_transform.csv\", index_col=0)\n",
    "\n",
    "print(results_inverse.L0.mean())\n",
    "print(results_inverse.L2.mean())\n",
    "print(results_inverse.feasibility.mean())\n",
    "print(results_inverse.violation.mean())\n",
    "print(results_inverse.success.mean())\n",
    "print(results_inverse.shape[0])\n",
    "print(results_inverse['time (seconds)'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_raw = pd.read_csv(f\"Results/adult_raw_data_n_{n_test}.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_inverse['method'] = 'MCCE'\n",
    "true_raw['method'] = 'Original'\n",
    "temp = pd.concat([results_inverse, true_raw], axis=0)\n",
    "\n",
    "cols = ['method', 'age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', \\\n",
    "       'hours-per-week', 'marital-status', 'native-country', \\\n",
    "       'occupation', 'race', 'relationship', 'sex', 'workclass']\n",
    "\n",
    "to_write = temp[cols].loc[[1, 31, 122, 124]].sort_index()\n",
    "to_write.columns = cols\n",
    "# to_write.sort_values(['Method'], inplace=True, ascending=False)\n",
    "\n",
    "to_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_path = \"Data/adult.data\"\n",
    "test_path = \"Data/adult.test\"\n",
    "train = pd.read_csv(train_path, sep=\", \", header=None, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'])\n",
    "test = pd.read_csv(test_path, skiprows=1, sep=\", \", header=None, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'])\n",
    "df = pd.concat([train, test], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in [\"workclass\", \"marital-status\", \"occupation\", \"relationship\", \"sex\", \"race\", \"native-country\"]:\n",
    "    d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "    for i, ind in enumerate(d):\n",
    "        if i <= 3:\n",
    "            d[i] = i\n",
    "        else:\n",
    "            d[i] = 3\n",
    "    mapping = d.to_dict()\n",
    "    dct = {v: k for k, v in mapping.items()}\n",
    "\n",
    "    to_write[feature] = [dct[item] for item in to_write[feature]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'marital-status'\n",
    "dct = {'Married-civ-spouse': 'MCS', 'Never-married': 'NM', 'Divorced': 'D', 'Married-AF-spouse': 'MAFS'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "feature = 'native-country'\n",
    "dct = {'United-States': 'US', 'Holand-Netherlands': 'HS'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "feature = 'occupation'\n",
    "dct = {'Exec-managerial': 'EM', 'Armed-Forces': 'AF', 'Prof-specialty': 'P'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "feature = 'race'\n",
    "dct = {'White': 'W', 'Black': 'B', 'Asian-Pac-Islander': 'API'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "feature = 'relationship'\n",
    "dct = {'Husband': 'H', 'Own-child': 'OC'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "feature = 'sex'\n",
    "dct = {'Male': 'M'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "feature = 'workclass'\n",
    "dct = {'Self-emp-not-inc': 'SENI', 'Private': 'P', 'Never-worked': 'NW'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_write.head(1)\n",
    "print(to_write.to_latex(index=False, float_format=\"%.0f\", ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature = 'workclass'\n",
    "# d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "# for i, ind in enumerate(d):\n",
    "#     if i <= 3:\n",
    "#         d[i] = i\n",
    "#     else:\n",
    "#         d[i] = 3\n",
    "\n",
    "# mapping = d.to_dict()\n",
    "# dct = {v: k for k, v in mapping.items()}\n",
    "\n",
    "# to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "# feature = 'marital-status'\n",
    "# d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "# for i, ind in enumerate(d):\n",
    "#     if i <= 3:\n",
    "#         d[i] = i\n",
    "#     else:\n",
    "#         d[i] = 3\n",
    "# mapping = d.to_dict()\n",
    "# dct = {v: k for k, v in mapping.items()}\n",
    "\n",
    "# to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "# feature = 'occupation'\n",
    "# d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "# for i, ind in enumerate(d):\n",
    "#     if i <= 3:\n",
    "#         d[i] = i\n",
    "#     else:\n",
    "#         d[i] = 3\n",
    "# mapping = d.to_dict()\n",
    "# dct = {v: k for k, v in mapping.items()}\n",
    "\n",
    "# to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "# feature = 'relationship'\n",
    "# d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "# for i, ind in enumerate(d):\n",
    "#     if i <= 3:\n",
    "#         d[i] = i\n",
    "#     else:\n",
    "#         d[i] = 3\n",
    "# mapping = d.to_dict()\n",
    "# dct = {v: k for k, v in mapping.items()}\n",
    "\n",
    "# to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "# feature = 'sex'\n",
    "# d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "# for i, ind in enumerate(d):\n",
    "#     if i <= 3:\n",
    "#         d[i] = i\n",
    "#     else:\n",
    "#         d[i] = 3\n",
    "# mapping = d.to_dict()\n",
    "# dct = {v: k for k, v in mapping.items()}\n",
    "\n",
    "# to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "# feature = 'race'\n",
    "# d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "# for i, ind in enumerate(d):\n",
    "#     if i <= 3:\n",
    "#         d[i] = i\n",
    "#     else:\n",
    "#         d[i] = 3\n",
    "# mapping = d.to_dict()\n",
    "# dct = {v: k for k, v in mapping.items()}\n",
    "\n",
    "# to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "# feature = 'native-country'\n",
    "# d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "# for i, ind in enumerate(d):\n",
    "#     if i <= 3:\n",
    "#         d[i] = i\n",
    "#     else:\n",
    "#         d[i] = 3\n",
    "# mapping = d.to_dict()\n",
    "# dct = {v: k for k, v in mapping.items()}\n",
    "\n",
    "# to_write[feature] = [dct[item] for item in to_write[feature]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_write\n",
    "# feature = 'workclass'\n",
    "# [dct[item] for item in to_write[feature]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature = 'marital-status'\n",
    "# dct = {'Married-civ-spouse': 'MCS', 'Never-married': 'NM', 'Divorced': 'D', 'Married-AF-spouse': 'MAFS'}\n",
    "# to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "# feature = 'native-country'\n",
    "# dct = {'United-States': 'US', 'Holand-Netherlands': 'HS'}\n",
    "# to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "# feature = 'occupation'\n",
    "# dct = {'Exec-managerial': 'EM', 'Armed-Forces': 'AF', 'Prof-specialty': 'P'}\n",
    "# to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "# feature = 'race'\n",
    "# dct = {'White': 'W', 'Black': 'B', 'Asian-Pac-Islander': 'API'}\n",
    "# to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "# feature = 'relationship'\n",
    "# dct = {'Husband': 'H', 'Own-child': 'OC'}\n",
    "# to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "# feature = 'sex'\n",
    "# dct = {'Male': 'M'}\n",
    "# to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "\n",
    "# feature = 'workclass'\n",
    "# dct = {'Self-emp-not-inc': 'SENI', 'Private': 'P', 'Never-worked': 'NW'}\n",
    "# to_write[feature] = [dct[item] for item in to_write[feature]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_write.head(1)\n",
    "# print(to_write.to_latex(index=False, float_format=\"%.0f\", ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# data = df\n",
    "# synth = synth_df\n",
    "# test = test_factual\n",
    "# response = y_col\n",
    "# inverse_transform = dataset.inverse_transform\n",
    "# cutoff = 0.5\n",
    "# # Predict response of generated data\n",
    "# synth[response] = ml_model.predict(synth)\n",
    "# synth_positive = synth[synth[response]>=cutoff] # drop negative responses\n",
    "\n",
    "# # Duplicate original test observations N times where N is number of positive counterfactuals\n",
    "# n_counterfactuals = synth_positive.groupby(synth_positive.index).size()\n",
    "# n_counterfactuals = pd.DataFrame(n_counterfactuals, columns = ['N'])\n",
    "\n",
    "# test_repeated = test.copy()\n",
    "\n",
    "# test_repeated = test_repeated.join(n_counterfactuals)\n",
    "# test_repeated.dropna(inplace = True)\n",
    "\n",
    "# test_repeated = test_repeated.reindex(test_repeated.index.repeat(test_repeated.N))\n",
    "# test_repeated.drop(['N'], axis=1, inplace=True)\n",
    "\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# synth=synth_positive\n",
    "# test=test_repeated\n",
    "\n",
    "# features = synth.columns.to_list()\n",
    "# features.remove(response)\n",
    "\n",
    "# synth_metrics = synth.copy()\n",
    "# synth.sort_index(inplace=True)\n",
    "\n",
    "# cols = data.columns\n",
    "# cols.drop(response)\n",
    "\n",
    "# feas_results = []\n",
    "# nbrs = NearestNeighbors(n_neighbors=5).fit(synth[cols].values)\n",
    "\n",
    "# for i, row in synth[cols].iterrows():\n",
    "#     knn = nbrs.kneighbors(row.values.reshape((1, -1)), 5, return_distance=True)[0]\n",
    "    \n",
    "#     feas_results.append(np.mean(knn))\n",
    "\n",
    "# synth_metrics['feasibility'] = feas_results\n",
    "\n",
    "# synth_metrics['success'] = 1\n",
    "\n",
    "# # 6) Success\n",
    "# synth_metrics['success'] = 1\n",
    "# synth.sort_index(inplace=True)\n",
    "\n",
    "# categorical_encoded = []\n",
    "# for x in dataset.df.columns:\n",
    "#     if x not in dataset.continuous:\n",
    "#         if x not in dataset.target:\n",
    "#             categorical_encoded.append(x)\n",
    "\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# len(synth.index.unique())\n",
    "# test.loc[1][features].iloc[1:2]\n",
    "\n",
    "# 1) Distance: Sparsity and Euclidean distance\n",
    "# factual = test[features].sort_index().to_numpy()\n",
    "# counterfactuals = synth[features].sort_index().to_numpy()\n",
    "\n",
    "# cfs_continuous = synth[dataset.continuous].sort_index().to_numpy()\n",
    "# cfs_categorical = synth[categorical_encoded].sort_index().to_numpy()\n",
    "\n",
    "# factual_continuous = test[dataset.continuous].sort_index().to_numpy()\n",
    "# factual_categorical = test[categorical_encoded].sort_index().to_numpy()\n",
    "\n",
    "# delta_cont = factual_continuous - cfs_continuous\n",
    "# delta_cat = factual_categorical - cfs_categorical\n",
    "\n",
    "# delta_cat = np.where(np.abs(delta_cat) > 0, 1, 0)\n",
    "\n",
    "# delta = np.concatenate((delta_cont, delta_cat), axis=1)\n",
    "# d1 = np.sum(np.invert(np.isclose(delta, np.zeros_like(delta), atol=1e-5)), axis=1, dtype=float).tolist() # sparsity\n",
    "# d2 = np.sum(np.abs(delta), axis=1, dtype=float).tolist() # manhatten distance\n",
    "# d3 = np.sum(np.square(np.abs(delta)), axis=1, dtype=np.float).tolist() # euclidean distance\n",
    "\n",
    "# synth_metrics['L0'] = d1\n",
    "# synth_metrics['L1'] = d2\n",
    "# synth_metrics['L2'] = d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_decoded_cfs = pd.DataFrame(scaler.inverse_transform(synth[continuous]), columns=continuous)\n",
    "# df_decoded_cfs.index = synth.index\n",
    "\n",
    "# df_decoded_cfs = pd.concat([df_decoded_cfs, synth[categorical]], axis=1)\n",
    "# df_decoded_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transform(df, continuous, categorical, scaler):\n",
    "#     df_transform = scaler.transform(df[continuous])\n",
    "#     df_transform = pd.DataFrame(df_transform, columns=continuous, index=df.index)\n",
    "#     return pd.concat([df_transform, df[categorical]], axis=1)\n",
    "\n",
    "\n",
    "# def inverse_transform(df, continuous, categorical, scaler):\n",
    "#     df_transform = scaler.inverse_transform(df[continuous])\n",
    "#     df_transform = pd.DataFrame(df_transform, columns=continuous, index=df.index)\n",
    "#     return pd.concat([df_transform, df[categorical]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def intersection(lst1, lst2):\n",
    "#     return list(set(lst1) & set(lst2))\n",
    "\n",
    "\n",
    "# df_decoded_cfs = dataset.inverse_transform(synth)\n",
    "\n",
    "# df_factuals = dataset.inverse_transform(test)\n",
    "\n",
    "# # check continuous using np.isclose to allow for very small numerical differences\n",
    "# cfs_continuous_immutable = df_decoded_cfs[\n",
    "#     intersection(dataset.continuous, fixed_features)\n",
    "# ]\n",
    "\n",
    "# factual_continuous_immutable = df_factuals[\n",
    "#     intersection(dataset.continuous, dataset.immutables)\n",
    "# ]\n",
    "\n",
    "# continuous_violations = np.invert(\n",
    "#     np.isclose(cfs_continuous_immutable, factual_continuous_immutable)\n",
    "# )\n",
    "# continuous_violations = np.sum(continuous_violations, axis=1).reshape(\n",
    "#     (-1, 1)\n",
    "# ) \n",
    "\n",
    "# # check categorical by boolean comparison\n",
    "# cfs_categorical_immutable = df_decoded_cfs[\n",
    "#     intersection(dataset.categorical, dataset.immutables)\n",
    "# ]\n",
    "# # print(cfs_categorical_immutable)\n",
    "# factual_categorical_immutable = df_factuals[\n",
    "#     intersection(dataset.categorical, dataset.immutables)\n",
    "# ]\n",
    "\n",
    "\n",
    "# cfs_categorical_immutable.sort_index(inplace=True)\n",
    "# factual_categorical_immutable.sort_index(inplace=True)\n",
    "# cfs_categorical_immutable.index.name = None\n",
    "\n",
    "# categorical_violations = cfs_categorical_immutable != factual_categorical_immutable\n",
    "# categorical_violations = np.sum(categorical_violations.values, axis=1).reshape(\n",
    "#     (-1, 1)\n",
    "# )  # sum over features\n",
    "\n",
    "# synth_metrics['violation'] = continuous_violations + categorical_violations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = synth_metrics.copy()\n",
    "# results_sparse = pd.DataFrame(columns=results.columns)\n",
    "\n",
    "# for idx in list(set(results.index)):\n",
    "#     idx_df = results.loc[idx]\n",
    "#     if(isinstance(idx_df, pd.DataFrame)): # If you have multiple rows\n",
    "#         sparse = min(idx_df.L0) # 1) find least # features changed\n",
    "#         sparse_df = idx_df[idx_df.L0 == sparse] \n",
    "#         closest = min(sparse_df.L2) # find smallest Gower distance\n",
    "#         close_df = sparse_df[sparse_df.L2 == closest]\n",
    "\n",
    "#         if(close_df.shape[0]>1):\n",
    "#             highest_feasibility = max(close_df.feasibility) #  3) find most feasible\n",
    "#             close_df = close_df[close_df.feasibility == highest_feasibility].head(1)\n",
    "\n",
    "#     else: # if you have only one row - return that row\n",
    "#         close_df = idx_df.to_frame().T\n",
    "        \n",
    "#     results_sparse = pd.concat([results_sparse, close_df], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_sparse[['L0', 'L1', 'L2', 'feasibility', 'violation', 'success']].mean()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea38de303447ace9d448c28089670fa84711b12cac6767c435896f96584513e1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('carla_github')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
