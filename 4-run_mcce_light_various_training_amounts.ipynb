{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n",
      "balance on test set 0.8131345863037374, balance on test set 0.8191834089436163\n",
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/carla/models/catalog/ANN_TORCH/model_ann.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5018 Acc: 0.7280\n",
      "\n",
      "test Loss: 0.4022 Acc: 0.8192\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.4002 Acc: 0.8283\n",
      "\n",
      "test Loss: 0.3704 Acc: 0.8471\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.3796 Acc: 0.8356\n",
      "\n",
      "test Loss: 0.3557 Acc: 0.8419\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.3665 Acc: 0.8423\n",
      "\n",
      "test Loss: 0.3405 Acc: 0.8477\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.3620 Acc: 0.8438\n",
      "\n",
      "test Loss: 0.3483 Acc: 0.8464\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.3589 Acc: 0.8445\n",
      "\n",
      "test Loss: 0.3409 Acc: 0.8542\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.3592 Acc: 0.8434\n",
      "\n",
      "test Loss: 0.3361 Acc: 0.8555\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.3579 Acc: 0.8451\n",
      "\n",
      "test Loss: 0.3358 Acc: 0.8529\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.3564 Acc: 0.8445\n",
      "\n",
      "test Loss: 0.3367 Acc: 0.8548\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.3559 Acc: 0.8440\n",
      "\n",
      "test Loss: 0.3383 Acc: 0.8516\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.3564 Acc: 0.8471\n",
      "\n",
      "test Loss: 0.3534 Acc: 0.8542\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.3556 Acc: 0.8447\n",
      "\n",
      "test Loss: 0.3376 Acc: 0.8535\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.3557 Acc: 0.8460\n",
      "\n",
      "test Loss: 0.3478 Acc: 0.8483\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.3560 Acc: 0.8451\n",
      "\n",
      "test Loss: 0.3391 Acc: 0.8620\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.3553 Acc: 0.8449\n",
      "\n",
      "test Loss: 0.3326 Acc: 0.8529\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.3546 Acc: 0.8447\n",
      "\n",
      "test Loss: 0.3349 Acc: 0.8542\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.3543 Acc: 0.8460\n",
      "\n",
      "test Loss: 0.3347 Acc: 0.8633\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.3543 Acc: 0.8440\n",
      "\n",
      "test Loss: 0.3499 Acc: 0.8600\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.3543 Acc: 0.8421\n",
      "\n",
      "test Loss: 0.3377 Acc: 0.8600\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.3533 Acc: 0.8442\n",
      "\n",
      "test Loss: 0.3341 Acc: 0.8600\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.3541 Acc: 0.8458\n",
      "\n",
      "test Loss: 0.3323 Acc: 0.8626\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.3533 Acc: 0.8462\n",
      "\n",
      "test Loss: 0.3345 Acc: 0.8581\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.3546 Acc: 0.8421\n",
      "\n",
      "test Loss: 0.3316 Acc: 0.8561\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.3539 Acc: 0.8434\n",
      "\n",
      "test Loss: 0.3373 Acc: 0.8633\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.3537 Acc: 0.8432\n",
      "\n",
      "test Loss: 0.3385 Acc: 0.8620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from carla.data.catalog import OnlineCatalog\n",
    "from carla.models.catalog import MLModelCatalog\n",
    "from carla.models.negative_instances import predict_negative_instances, predict_label\n",
    "\n",
    "import torch\n",
    "\n",
    "from mcce import MCCE\n",
    "\n",
    "## FOR EACH DATA SET you have to adjust n below - \n",
    "## for adult and gmc, I use 100, 1000, 10000 and the size of the data set\n",
    "## for compas, I use 100, 1000, 5000, and the size of the data set \n",
    "\n",
    "\n",
    "data_name = \"adult\"\n",
    "data_name = 'give_me_some_credit'\n",
    "data_name = 'compas'\n",
    "n_test = 100\n",
    "seed = 1\n",
    "\n",
    "dataset = OnlineCatalog(data_name)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "ml_model = MLModelCatalog(\n",
    "        dataset, \n",
    "        model_type=\"ann\", \n",
    "        load_online=False, \n",
    "        backend=\"pytorch\"\n",
    "        )\n",
    "if data_name == 'adult':\n",
    "    ml_model.train(\n",
    "    learning_rate=0.002,\n",
    "    epochs=20,\n",
    "    batch_size=1024,\n",
    "    hidden_size=[18, 9, 3],\n",
    "    force_train=True, # don't forget to add this or it might load an older model from disk\n",
    "    )\n",
    "elif data_name == 'give_me_some_credit':\n",
    "    ml_model.train(\n",
    "    learning_rate=0.002,\n",
    "    epochs=20,\n",
    "    batch_size=2048,\n",
    "    hidden_size=[18, 9, 3],\n",
    "    force_train=True, # don't forget to add this or it might load an older model from disk\n",
    "    )\n",
    "elif data_name == 'compas':\n",
    "    ml_model.train(\n",
    "    learning_rate=0.002,\n",
    "    epochs=25,\n",
    "    batch_size=25,\n",
    "    hidden_size=[18, 9, 3],\n",
    "    force_train=True, # don't forget to add this or it might load an older model from disk\n",
    "    )\n",
    "\n",
    "# (2) Find unhappy customers and choose which ones to make counterfactuals for\n",
    "\n",
    "factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "test_factual = factuals.iloc[:n_test]\n",
    "# test_factual_inverse = dataset.inverse_transform(test_factual)\n",
    "\n",
    "y_col = dataset.target\n",
    "features_and_response = dataset.df.columns\n",
    "cont_feat = dataset.continuous\n",
    "cat_feat = [x for x in features_and_response if x not in cont_feat] #  these have new names since encode_normalize_order_factuals()\n",
    "\n",
    "if data_name == 'adult': \n",
    "    fixed_features = ['age', 'sex_Male']\n",
    "    immutables = ['age', 'sex']\n",
    "elif data_name == 'give_me_some_credit':\n",
    "    fixed_features = ['age']\n",
    "    immutables = ['age']\n",
    "elif data_name == 'compas':\n",
    "    fixed_features = ['age', 'sex_Male', 'race_Other']\n",
    "    immutables = ['age', 'sex', 'race']\n",
    "\n",
    "#  Create dtypes for MCCE()\n",
    "dtypes = dict([(x, \"float\") for x in cont_feat])\n",
    "for x in cat_feat:\n",
    "    dtypes[x] = \"category\"\n",
    "df = (dataset.df).astype(dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset of Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "factual_indices = test_factual.index.to_list()\n",
    "all_indices = dataset.df.index.to_list()\n",
    "possible_train_indices = set(factual_indices) ^ set(all_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6072\n"
     ]
    }
   ],
   "source": [
    "dataset.df.shape\n",
    "print(len(possible_train_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/carla/models/catalog/ANN_TORCH/model_ann.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/carla/models/catalog/ANN_TORCH/model_ann.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "results = []\n",
    "for n in [100, 1000, 5000]: # [len(possible_train_indices)]:\n",
    "\n",
    "    for s in range(1): # range(5):\n",
    "\n",
    "        dim = dataset.df.shape[0]\n",
    "        print(dim)\n",
    "        random.seed(s)\n",
    "        rows = random.sample(possible_train_indices, n)\n",
    "        rows = np.sort(rows)\n",
    "\n",
    "        positives = (df.loc[rows]).copy()\n",
    "        positives[\"y\"] = predict_label(ml_model, positives)\n",
    "        positives = positives[positives[\"y\"] == 1]\n",
    "        positives = positives.drop(\"y\", axis=\"columns\")\n",
    "\n",
    "        positives = dataset.inverse_transform(positives)\n",
    "        test_factual_inverse = dataset.inverse_transform(test_factual)\n",
    "        test_factual_inverse.index.name = 'test'\n",
    "\n",
    "        import time\n",
    "        start = time.time()\n",
    "\n",
    "        synth = pd.merge(test_factual_inverse.reset_index()[dataset.immutables + ['test']], positives, on = dataset.immutables).set_index(['test']) # 'train',\n",
    "        synth = dataset.transform(synth) # go from normal to one-hot encoded\n",
    "\n",
    "        from mcce import MCCE\n",
    "\n",
    "        mcce = MCCE(fixed_features=fixed_features, immutables=immutables, \\\n",
    "            model=ml_model, continuous=dataset.continuous, categorical=dataset.categorical)\n",
    "\n",
    "        mcce.fit(df.drop(dataset.target, axis=1), dtypes)\n",
    "\n",
    "        mcce.postprocess(data=df, synth=synth, test=test_factual, response=y_col, \\\n",
    "        transform=None, inverse_transform=dataset.inverse_transform, cutoff=0.5)\n",
    "\n",
    "        timing = time.time() - start\n",
    "\n",
    "        mcce.results_sparse['time (seconds)'] = timing\n",
    "\n",
    "        results.append([mcce.results_sparse.L0.mean(), mcce.results_sparse.L2.mean(), mcce.results_sparse.feasibility.mean(), mcce.results_sparse.violation.mean(), mcce.results_sparse.shape[0], timing, n, s])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L0</th>\n",
       "      <th>L2</th>\n",
       "      <th>feasibility</th>\n",
       "      <th>violation</th>\n",
       "      <th>NCE</th>\n",
       "      <th>timing</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ntest</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2.562510</td>\n",
       "      <td>0.801110</td>\n",
       "      <td>0.072443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.4</td>\n",
       "      <td>0.495268</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1.816698</td>\n",
       "      <td>0.213898</td>\n",
       "      <td>0.047730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.2</td>\n",
       "      <td>1.378713</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>1.514000</td>\n",
       "      <td>0.096621</td>\n",
       "      <td>0.022430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.562577</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>1.490000</td>\n",
       "      <td>0.080221</td>\n",
       "      <td>0.020698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.477870</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             L0        L2  feasibility  violation    NCE    timing  seed\n",
       "Ntest                                                                   \n",
       "100    2.562510  0.801110     0.072443        0.0   59.4  0.495268   2.0\n",
       "1000   1.816698  0.213898     0.047730        0.0   98.2  1.378713   2.0\n",
       "5000   1.514000  0.096621     0.022430        0.0  100.0  4.562577   2.0\n",
       "6072   1.490000  0.080221     0.020698        0.0  100.0  5.477870   0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2 = pd.DataFrame(results, columns=['L0', 'L2', 'feasibility', 'violation', 'NCE', 'timing', 'Ntest', 'seed'])\n",
    "results2\n",
    "results2.groupby(['Ntest']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All of Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = dataset.df.copy()\n",
    "positives[\"y\"] = predict_label(ml_model, positives)\n",
    "positives = positives[positives[\"y\"] == 1]\n",
    "positives = positives.drop(\"y\", axis=\"columns\")\n",
    "\n",
    "positives = dataset.inverse_transform(positives)\n",
    "test_factual_inverse = dataset.inverse_transform(test_factual)\n",
    "test_factual_inverse.index.name = 'test'\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "synth = pd.merge(test_factual_inverse.reset_index()[dataset.immutables + ['test']], positives, on = dataset.immutables).set_index(['test']) # 'train',\n",
    "synth = dataset.transform(synth) # go from normal to one-hot encoded\n",
    "\n",
    "from mcce import MCCE\n",
    "\n",
    "mcce = MCCE(fixed_features=fixed_features, immutables=immutables, model=ml_model, continuous=dataset.continuous, categorical=dataset.categorical)\n",
    "\n",
    "mcce.fit(df.drop(dataset.target, axis=1), dtypes)\n",
    "\n",
    "mcce.postprocess(data=dataset.df, synth=synth, test=test_factual, response=y_col, \\\n",
    "    transform=None, inverse_transform=dataset.inverse_transform, cutoff=0.5)\n",
    "\n",
    "timing = time.time() - start\n",
    "print(timing)\n",
    "\n",
    "mcce.results_sparse['time (seconds)'] = timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append([mcce.results_sparse.L0.mean(), mcce.results_sparse.L2.mean(), mcce.results_sparse.feasibility.mean(), mcce.results_sparse.violation.mean(), mcce.results_sparse.shape[0], timing, 48000, 1])\n",
    "\n",
    "results2 = pd.DataFrame(results, columns=['L0', 'L2', 'feasibility', 'violation', 'NCE', 'timing', 'Ntest', 'seed'])\n",
    "results2\n",
    "results2.groupby(['Ntest']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_factual.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = mcce.results_sparse\n",
    "temp.to_csv(f\"/nr/samba/user/anr/pkg/MCCE_Python/Results/{data_name}_baseline_results_n_{n_test}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synth.index.name = None\n",
    "# synth\n",
    "# test_factual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=dataset.df\n",
    "# test=test_factual\n",
    "# response=y_col\n",
    "# transform=None\n",
    "# inverse_transform=dataset.inverse_transform\n",
    "# cutoff=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict response of generated data\n",
    "# synth[response] = ml_model.predict(synth)\n",
    "# synth_positive = synth[synth[response]>=cutoff] # drop negative responses\n",
    "\n",
    "\n",
    "# # Duplicate original test observations N times where N is number of positive counterfactuals\n",
    "# n_counterfactuals = synth_positive.groupby(synth_positive.index).size()\n",
    "# n_counterfactuals = pd.DataFrame(n_counterfactuals, columns = ['N'])\n",
    "\n",
    "# test_repeated = test.copy()\n",
    "\n",
    "# test_repeated = test_repeated.join(n_counterfactuals)\n",
    "# test_repeated.dropna(inplace = True)\n",
    "\n",
    "# test_repeated = test_repeated.reindex(test_repeated.index.repeat(test_repeated.N))\n",
    "# test_repeated.drop(['N'], axis=1, inplace=True)\n",
    "\n",
    "# test = test_repeated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_repeated.sort_index(inplace=True)\n",
    "# test_repeated.iloc[804]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = synth.columns.to_list()\n",
    "# features.remove(response)\n",
    "\n",
    "# synth_metrics = synth.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synth.sort_index(inplace=True)\n",
    "# synth.iloc[804:806]\n",
    "# .iloc[804:806]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def intersection(lst1, lst2):\n",
    "#     return list(set(lst1) & set(lst2))\n",
    "\n",
    "# df_decoded_cfs = inverse_transform(synth.copy())\n",
    "\n",
    "# df_factuals = inverse_transform(test.copy())\n",
    "\n",
    "# # check continuous using np.isclose to allow for very small numerical differences\n",
    "# cfs_continuous_immutable = df_decoded_cfs[\n",
    "#     intersection(dataset.continuous, fixed_features)\n",
    "# ]\n",
    "# factual_continuous_immutable = df_factuals[\n",
    "#     intersection(dataset.continuous, dataset.immutables)\n",
    "# ]\n",
    "# # print(cfs_continuous_immutable)\n",
    "# print(factual_continuous_immutable.shape)\n",
    "\n",
    "# continuous_violations = np.invert(\n",
    "#     np.isclose(cfs_continuous_immutable, factual_continuous_immutable)\n",
    "# )\n",
    "# continuous_violations = np.sum(continuous_violations, axis=1).reshape(\n",
    "#     (-1, 1)\n",
    "# )  # sum over features\n",
    "\n",
    "# cfs_categorical_immutable = df_decoded_cfs[\n",
    "#     intersection(dataset.categorical, dataset.immutables)\n",
    "# ]\n",
    "# factual_categorical_immutable = df_factuals[\n",
    "#     intersection(dataset.categorical, dataset.immutables)\n",
    "# ]\n",
    "\n",
    "# cfs_categorical_immutable.sort_index(inplace=True)\n",
    "# factual_categorical_immutable.sort_index(inplace=True)\n",
    "# cfs_categorical_immutable.index.name = None\n",
    "\n",
    "# categorical_violations = cfs_categorical_immutable != factual_categorical_immutable\n",
    "\n",
    "# categorical_violations = np.sum(categorical_violations.values, axis=1).reshape(\n",
    "#             (-1, 1)\n",
    "#         )\n",
    "\n",
    "\n",
    "# factual_categorical_immutable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blah = []\n",
    "# for x in (continuous_violations + categorical_violations):\n",
    "#     blah.append(x[0])\n",
    "# np.mean(blah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, x in enumerate(blah):\n",
    "#     if x == 1:\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcce.results_sparse.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_factual.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if you want to find out which data point the test observation \"found\" in the training data\n",
    "\n",
    "# idx = 1\n",
    "# temp = mcce.results_sparse.iloc[idx:(idx + 1)]\n",
    "\n",
    "# feat = ['age', 'fnlwgt', 'education-num', 'capital-gain']\n",
    "\n",
    "# to_show = pd.merge(temp[feat], dataset.df.reset_index(), on = feat).set_index('index')\n",
    "\n",
    "# to_show.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(mcce.results_sparse.violation.mean())\n",
    "# print(mcce.results_sparse.L0.mean())\n",
    "# print(mcce.results_sparse.L1.mean())\n",
    "# print(mcce.results_sparse.L2.mean())\n",
    "\n",
    "# print(mcce.results_sparse.feasibility.mean())\n",
    "# print(mcce.results_sparse.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcce.results_sparse"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea38de303447ace9d448c28089670fa84711b12cac6767c435896f96584513e1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('carla_github')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
