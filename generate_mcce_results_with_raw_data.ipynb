{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "n_test = 100\n",
    "K = 1000\n",
    "\n",
    "import torch\n",
    "\n",
    "from mcce import MCCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "from carla.data.catalog import OnlineCatalog\n",
    "import pandas as pd\n",
    "\n",
    "train_path = \"/nr/samba/user/anr/pkg/MCCE/Datasets/Adult/adult.data\"\n",
    "test_path = \"/nr/samba/user/anr/pkg/MCCE/Datasets/Adult/adult.test\"\n",
    "train = pd.read_csv(train_path, sep=\", \", header=None, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'])\n",
    "test = pd.read_csv(test_path, skiprows=1, sep=\", \", header=None, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'])\n",
    "\n",
    "df = train\n",
    "\n",
    "# df = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "# df.to_csv(\"/nr/samba/user/anr/pkg/MCCE/Datasets/Adult/Adult_train_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'>50K': '>50K', '>50K.': '>50K', '<=50K': '<=50K', '<=50K.': '<=50K'}\n",
    "\n",
    "df['income'] = [mapping[item] for item in df['income']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'workclass'\n",
    "d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "for i, ind in enumerate(d):\n",
    "    d[i] = i\n",
    "mapping = d.to_dict()\n",
    "df[feature] = [mapping[item] for item in df[feature]]\n",
    "\n",
    "feature = 'education'\n",
    "d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "for i, ind in enumerate(d):\n",
    "    d[i] = i\n",
    "mapping = d.to_dict()\n",
    "df[feature] = [mapping[item] for item in df[feature]]\n",
    "\n",
    "feature = 'marital-status'\n",
    "d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "for i, ind in enumerate(d):\n",
    "    d[i] = i\n",
    "mapping = d.to_dict()\n",
    "df[feature] = [mapping[item] for item in df[feature]]\n",
    "\n",
    "feature = 'occupation'\n",
    "d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "for i, ind in enumerate(d):\n",
    "    d[i] = i\n",
    "mapping = d.to_dict()\n",
    "df[feature] = [mapping[item] for item in df[feature]]\n",
    "\n",
    "feature = 'relationship'\n",
    "d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "for i, ind in enumerate(d):\n",
    "    d[i] = i\n",
    "mapping = d.to_dict()\n",
    "df[feature] = [mapping[item] for item in df[feature]]\n",
    "\n",
    "feature = 'sex'\n",
    "d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "for i, ind in enumerate(d):\n",
    "    d[i] = i\n",
    "mapping = d.to_dict()\n",
    "df[feature] = [mapping[item] for item in df[feature]]\n",
    "\n",
    "feature = 'race'\n",
    "d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "for i, ind in enumerate(d):\n",
    "    d[i] = i\n",
    "mapping = d.to_dict()\n",
    "df[feature] = [mapping[item] for item in df[feature]]\n",
    "\n",
    "feature = 'native-country'\n",
    "d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "for i, ind in enumerate(d):\n",
    "    d[i] = i\n",
    "mapping = d.to_dict()\n",
    "df[feature] = [mapping[item] for item in df[feature]]\n",
    "\n",
    "feature = 'income'\n",
    "d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "for i, ind in enumerate(d):\n",
    "    d[i] = i\n",
    "mapping = d.to_dict()\n",
    "df[feature] = [mapping[item] for item in df[feature]]\n",
    "\n",
    "df.drop(['education'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/nr/samba/user/anr/pkg/MCCE/Datasets/Adult/train_not_normalized_data_from_carla.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['workclass', 'occupation', 'relationship', 'native-country']].groupby(by = 'workclass').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = ['age',\n",
    "    'fnlwgt',\n",
    "    'education-num',\n",
    "    'capital-gain',\n",
    "    'hours-per-week',\n",
    "    'capital-loss']\n",
    "\n",
    "categorical = ['marital-status',\n",
    "'native-country',\n",
    "'occupation',\n",
    "'race',\n",
    "'relationship',\n",
    "'sex',\n",
    "'workclass', \n",
    "'income']\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler().fit(df[continuous])\n",
    "df_scaled = scaler.transform(df[continuous])\n",
    "df_scaled = pd.DataFrame(df_scaled)\n",
    "df_scaled.columns = continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = pd.concat([df_scaled, df[categorical]], axis=1) # axis = 0 is index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.to_csv(\"/nr/samba/user/anr/pkg/MCCE/Datasets/Adult/for_CsvCatalog.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carla.data.catalog import CsvCatalog\n",
    "\n",
    "continuous = [\"age\", \"fnlwgt\", \"education-num\", \"capital-gain\", \"hours-per-week\", \"capital-loss\"]\n",
    "categorical = [\"marital-status\", \"native-country\", \"occupation\", \"race\", \"relationship\", \"sex\", \"workclass\"]\n",
    "immutable = [\"age\", \"sex\"]\n",
    "\n",
    "dataset = CsvCatalog(file_path=\"/nr/samba/user/anr/pkg/MCCE/Datasets/Adult/for_CsvCatalog.csv\",\n",
    "                     continuous=continuous,\n",
    "                     categorical=categorical,\n",
    "                     immutables=immutable,\n",
    "                     target='income',\n",
    "                     scaling_method=None,\n",
    "                     encoding_method=None,\n",
    "                     )\n",
    "\n",
    "# dataset.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carla.models.catalog import MLModelCatalog\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "ml_model = MLModelCatalog(\n",
    "        dataset, \n",
    "        model_type=\"ann\", \n",
    "        load_online=False, \n",
    "        backend=\"pytorch\"\n",
    "    )\n",
    "\n",
    "\n",
    "ml_model.train(\n",
    "learning_rate=0.002,\n",
    "epochs=20,\n",
    "batch_size=1024,\n",
    "hidden_size=[18, 9, 3],\n",
    "force_train=True, # don't forget to add this or it might load an older model from disk\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carla.models.negative_instances import predict_negative_instances\n",
    "\n",
    "factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "test_factual = factuals.iloc[:n_test]\n",
    "# test_factual_inverse = dataset.inverse_transform(test_factual)\n",
    "\n",
    "y_col = dataset.target\n",
    "features_and_response = dataset.df.columns\n",
    "cont_feat = dataset.continuous\n",
    "cat_feat = [x for x in features_and_response if x not in cont_feat] #  these have new names since encode_normalize_order_factuals()\n",
    "\n",
    "fixed_features = ['age', 'sex']\n",
    "\n",
    "#  Create dtypes for MCCE()\n",
    "dtypes = dict([(x, \"float\") for x in cont_feat])\n",
    "for x in cat_feat:\n",
    "    dtypes[x] = \"category\"\n",
    "df = (dataset.df).astype(dtypes)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "# (3) Fit MCCE object\n",
    "print(\"Fitting MCCE model...\")\n",
    "mcce = MCCE(fixed_features=fixed_features, model=ml_model, seed=1)\n",
    "mcce.fit(df.drop(y_col, axis=1), dtypes)\n",
    "print(\"Generating counterfactuals with MCCE...\")\n",
    "synth_df = mcce.generate(test_factual.drop(y_col, axis=1), k=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) Postprocess generated counterfactuals\n",
    "print(\"Postprocessing counterfactuals with MCCE...\")\n",
    "mcce.postprocess(df, synth_df, test_factual, y_col, scaler=dataset.inverse_transform, cutoff=0.5)\n",
    "timing = time.time() - start\n",
    "print(timing)\n",
    "\n",
    "mcce.results_sparse['time (seconds)'] = timing\n",
    "\n",
    "# 20 minutes for give_me_some_credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcce.results_sparse.to_csv(f\"/nr/samba/user/anr/pkg/MCCE_Python/adult_mcce_results_raw_data_k_{K}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mcce.results_sparse.)\n",
    "print(mcce.results_sparse.L0.mean())\n",
    "print(mcce.results_sparse.L1.mean())\n",
    "print(mcce.results_sparse.L2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_sparse = mcce.results_sparse\n",
    "results_sparse.index.rename('index', inplace=True)\n",
    "results_sparse.groupby('index').size().sort_values(ascending=False)\n",
    "#results_sparse.loc[64].iloc[0]#[[dataset.categorical + dataset.continuous]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_decoded_cfs = pd.DataFrame(scaler.inverse_transform(df_cfs.copy()[continuous]))\n",
    "# df_decoded_cfs.columns = continuous\n",
    "# df_decoded_cfs.index = df_cfs.index\n",
    "# df_decoded_cfs = pd.concat([df_decoded_cfs, df_cfs.copy()[categorical]], axis=1)\n",
    "\n",
    "# df_factuals = pd.DataFrame(scaler.inverse_transform(test_repeated.copy()[continuous]))\n",
    "# df_factuals.columns = continuous\n",
    "# df_factuals.index = test_repeated.index\n",
    "# df_factuals = pd.concat([df_factuals, test_repeated.copy()[categorical]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mcce.results_sparse.feasibility.mean())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea38de303447ace9d448c28089670fa84711b12cac6767c435896f96584513e1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('carla_github')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
