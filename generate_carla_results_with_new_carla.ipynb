{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for Tables 1, 2, 3 for CARLA methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n"
     ]
    }
   ],
   "source": [
    "from carla.data.catalog import OnlineCatalog\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# load catalog dataset\n",
    "data_name = \"adult\"\n",
    "# data_name = \"give_me_some_credit\"\n",
    "# data_name = 'compas'\n",
    "dataset = OnlineCatalog(data_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance on test set 0.23883245958934032, balance on test set 0.2408256880733945\n",
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/carla/models/catalog/ANN_TORCH/model_ann.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4668 Acc: 0.7734\n",
      "\n",
      "test Loss: 0.4055 Acc: 0.8005\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.3946 Acc: 0.8121\n",
      "\n",
      "test Loss: 0.3910 Acc: 0.8189\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.3784 Acc: 0.8222\n",
      "\n",
      "test Loss: 0.3747 Acc: 0.8226\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.3655 Acc: 0.8290\n",
      "\n",
      "test Loss: 0.3600 Acc: 0.8324\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.3535 Acc: 0.8343\n",
      "\n",
      "test Loss: 0.3505 Acc: 0.8373\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.3460 Acc: 0.8372\n",
      "\n",
      "test Loss: 0.3472 Acc: 0.8389\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.3431 Acc: 0.8387\n",
      "\n",
      "test Loss: 0.3450 Acc: 0.8402\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.3405 Acc: 0.8402\n",
      "\n",
      "test Loss: 0.3435 Acc: 0.8384\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.3404 Acc: 0.8389\n",
      "\n",
      "test Loss: 0.3376 Acc: 0.8396\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.3348 Acc: 0.8421\n",
      "\n",
      "test Loss: 0.3421 Acc: 0.8400\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.3348 Acc: 0.8411\n",
      "\n",
      "test Loss: 0.3362 Acc: 0.8426\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.3345 Acc: 0.8401\n",
      "\n",
      "test Loss: 0.3339 Acc: 0.8435\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.3313 Acc: 0.8430\n",
      "\n",
      "test Loss: 0.3334 Acc: 0.8426\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.3296 Acc: 0.8442\n",
      "\n",
      "test Loss: 0.3353 Acc: 0.8435\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.3324 Acc: 0.8436\n",
      "\n",
      "test Loss: 0.3366 Acc: 0.8395\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.3311 Acc: 0.8431\n",
      "\n",
      "test Loss: 0.3449 Acc: 0.8354\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.3299 Acc: 0.8426\n",
      "\n",
      "test Loss: 0.3344 Acc: 0.8393\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.3296 Acc: 0.8435\n",
      "\n",
      "test Loss: 0.3302 Acc: 0.8430\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.3274 Acc: 0.8442\n",
      "\n",
      "test Loss: 0.3300 Acc: 0.8471\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.3295 Acc: 0.8434\n",
      "\n",
      "test Loss: 0.3283 Acc: 0.8449\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from carla.models.catalog import MLModelCatalog\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "ml_model = MLModelCatalog(\n",
    "        dataset, \n",
    "        model_type=\"ann\", \n",
    "        load_online=False, \n",
    "        backend=\"pytorch\"\n",
    "    )\n",
    "\n",
    "\n",
    "if data_name == 'adult':\n",
    "    ml_model.train(\n",
    "    learning_rate=0.002,\n",
    "    epochs=20,\n",
    "    batch_size=1024,\n",
    "    hidden_size=[18, 9, 3],\n",
    "    force_train=True, # don't forget to add this or it might load an older model from disk\n",
    "    )\n",
    "elif data_name == 'give_me_some_credit':\n",
    "    ml_model.train(\n",
    "    learning_rate=0.002,\n",
    "    epochs=20,\n",
    "    batch_size=2048,\n",
    "    hidden_size=[18, 9, 3],\n",
    "    force_train=True, # don't forget to add this or it might load an older model from disk\n",
    "    )\n",
    "elif data_name == 'compas':\n",
    "    ml_model.train(\n",
    "    learning_rate=0.002,\n",
    "    epochs=25,\n",
    "    batch_size=25,\n",
    "    hidden_size=[18, 9, 3],\n",
    "    force_train=True, # don't forget to add this or it might load an older model from disk\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8999147090860513"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "if data_name == 'adult':\n",
    "    y = dataset.df_test['income']\n",
    "elif data_name == 'give_me_some_credit':\n",
    "    y = dataset.df_test['SeriousDlqin2yrs']\n",
    "elif data_name == 'compas':\n",
    "    y = dataset.df_test['score']\n",
    "\n",
    "pred = ml_model.predict_proba(dataset.df_test)\n",
    "pred = [row[1] for row in pred]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=1)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carla.models.negative_instances import predict_negative_instances\n",
    "import carla.recourse_methods.catalog as recourse_catalog\n",
    "\n",
    "factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "test_factual = factuals.iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.inverse_transform(test_factual).loc[263]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml_model.predict_proba(dataset.df)[106]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "results = []\n",
    "for method in ['cchvae', 'cem-vae', 'revise', 'clue', 'crud', 'face']:\n",
    "    if data_name == 'adult':\n",
    "        cfs = pd.read_csv(\"Results/adult_manifold_results.csv\")\n",
    "    elif data_name == 'give_me_some_credit':\n",
    "        cfs = pd.read_csv(\"Results/give_me_some_credit_manifold_results.csv\")\n",
    "    elif data_name == 'compas':\n",
    "        cfs = pd.read_csv(\"Results/compas_manifold_results.csv\")\n",
    "    factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "    test_factual = factuals.iloc[:100]\n",
    "\n",
    "    cfs.rename(columns={'Unnamed: 0': 'index'}, inplace=True)\n",
    "    cfs.set_index(['index'], inplace=True)\n",
    "\n",
    "    df_cfs = cfs[cfs['method'] == method].drop(['method',\t'data'], axis=1)\n",
    "\n",
    "    nan_idx = df_cfs.index[df_cfs.isnull().any(axis=1)]\n",
    "\n",
    "    output_factuals = test_factual.copy()\n",
    "    output_counterfactuals = df_cfs.copy()\n",
    "\n",
    "    output_factuals = output_factuals.drop(index=nan_idx)\n",
    "    output_counterfactuals = output_counterfactuals.drop(index=nan_idx)\n",
    "\n",
    "    test_factual = output_factuals\n",
    "    df_cfs = output_counterfactuals\n",
    "\n",
    "    df_decoded_cfs = dataset.inverse_transform(df_cfs.copy())\n",
    "\n",
    "    df_factuals = dataset.inverse_transform(test_factual.copy())\n",
    "\n",
    "    # print(df_decoded_cfs)\n",
    "    # print(df_factuals)\n",
    "    # check continuous using np.isclose to allow for very small numerical differences\n",
    "    cfs_continuous_immutable = df_decoded_cfs[\n",
    "        intersection(dataset.continuous, dataset.immutables)\n",
    "    ]\n",
    "    factual_continuous_immutable = df_factuals[\n",
    "        intersection(dataset.continuous, dataset.immutables)\n",
    "    ]\n",
    "\n",
    "    continuous_violations = np.invert(\n",
    "        np.isclose(cfs_continuous_immutable, factual_continuous_immutable)\n",
    "    )\n",
    "    continuous_violations = np.sum(continuous_violations, axis=1).reshape(\n",
    "        (-1, 1)\n",
    "    )  # sum over features\n",
    "\n",
    "    # check categorical by boolean comparison\n",
    "    cfs_categorical_immutable = df_decoded_cfs[\n",
    "        intersection(dataset.categorical, dataset.immutables)\n",
    "    ]\n",
    "    factual_categorical_immutable = df_factuals[\n",
    "        intersection(dataset.categorical, dataset.immutables)\n",
    "    ]\n",
    "\n",
    "    categorical_violations = cfs_categorical_immutable != factual_categorical_immutable\n",
    "    categorical_violations = np.sum(categorical_violations.values, axis=1).reshape(\n",
    "        (-1, 1)\n",
    "    )  # sum over features\n",
    "\n",
    "    total_violations = continuous_violations + categorical_violations\n",
    "\n",
    "    for x in total_violations:\n",
    "        results.append(x[0])\n",
    "        \n",
    "final_results = cfs.copy()\n",
    "final_results.dropna(inplace=True)\n",
    "final_results['violations'] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "results = []\n",
    "for method in ['cchvae', 'cem-vae', 'revise', 'clue', 'crud', 'face']:\n",
    "    if data_name == 'adult':\n",
    "        cfs = pd.read_csv(\"Results/adult_manifold_results.csv\")\n",
    "    elif data_name == 'give_me_some_credit':\n",
    "        cfs = pd.read_csv(\"Results/give_me_some_credit_manifold_results.csv\")\n",
    "    elif data_name == 'compas':\n",
    "        cfs = pd.read_csv(\"Results/compas_manifold_results.csv\")\n",
    "    factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "    test_factual = factuals.iloc[:100]\n",
    "\n",
    "    cfs.rename(columns={'Unnamed: 0': 'index'}, inplace=True)\n",
    "    cfs.set_index(['index'], inplace=True)\n",
    "\n",
    "    df_cfs = cfs[cfs['method'] == method].drop(['method',\t'data'], axis=1)\n",
    "\n",
    "    nan_idx = df_cfs.index[df_cfs.isnull().any(axis=1)]\n",
    "\n",
    "    output_factuals = test_factual.copy()\n",
    "    output_counterfactuals = df_cfs.copy()\n",
    "\n",
    "    output_factuals = output_factuals.drop(index=nan_idx)\n",
    "    output_counterfactuals = output_counterfactuals.drop(index=nan_idx)\n",
    "\n",
    "    factual_without_nans = output_factuals\n",
    "    counterfactuals_without_nans = output_counterfactuals\n",
    "\n",
    "    # results.append(total_violations.sum())\n",
    "\n",
    "    columns = [\"Distance_1\", \"Distance_2\", \"Distance_3\", \"Distance_4\"]\n",
    "\n",
    "    \n",
    "    arr_f = ml_model.get_ordered_features(factual_without_nans).to_numpy()\n",
    "    arr_cf = ml_model.get_ordered_features(\n",
    "        counterfactuals_without_nans\n",
    "    ).to_numpy()\n",
    "\n",
    "    delta = arr_f - arr_cf \n",
    "\n",
    "    d1 = np.sum(np.invert(np.isclose(delta, np.zeros_like(delta))), axis=1, dtype=np.float).tolist()\n",
    "    d1_old = np.sum(delta.round(2) != 0, axis=1, dtype=np.float).tolist()\n",
    "\n",
    "    d2 = np.sum(np.abs(delta), axis=1, dtype=np.float).tolist()\n",
    "    d3 = np.sum(np.square(np.abs(delta)), axis=1, dtype=np.float).tolist()\n",
    "\n",
    "    results.append(pd.DataFrame({'L0': d1, 'L1': d2, 'L2': d3, 'time': df_cfs['time (seconds)'].mean()}))\n",
    "\n",
    "temp = pd.concat(results)\n",
    "temp.index = final_results.index\n",
    "final_results = pd.concat([final_results, temp], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for method in ['cchvae', 'cem-vae', 'revise', 'clue', 'crud', 'face']:\n",
    "    if data_name == 'adult':\n",
    "        cfs = pd.read_csv(\"Results/adult_manifold_results.csv\")\n",
    "        y_col = 'income'\n",
    "    elif data_name == 'give_me_some_credit':\n",
    "        cfs = pd.read_csv(\"Results/give_me_some_credit_manifold_results.csv\")\n",
    "        y_col = \"SeriousDlqin2yrs\"\n",
    "    elif data_name == 'compas':\n",
    "        cfs = pd.read_csv(\"Results/compas_manifold_results.csv\")\n",
    "        y_col = \"score\"\n",
    "\n",
    "    cfs.rename(columns={'Unnamed: 0': 'index'}, inplace=True)\n",
    "    cfs.set_index(['index'], inplace=True)\n",
    "\n",
    "    df_cfs = cfs[cfs['method'] == method].drop(['method',\t'data'], axis=1)\n",
    "    results.append(pd.DataFrame({'validity': df_cfs[y_col]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ml_model.predict_proba(final_results)\n",
    "temp2 = []\n",
    "temp3 = []\n",
    "for x in temp:\n",
    "    temp2.append(x[1]>= 0.5) #  >= 0.5\n",
    "\n",
    "    temp3.append(x[1]) #  >= 0.5\n",
    "    \n",
    "final_results['validity'] = temp2\n",
    "final_results['prediction'] = temp3\n",
    "final_results['validity'] = final_results['validity'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feasibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "results = []\n",
    "for method in ['cchvae', 'cem-vae', 'revise', 'clue', 'crud', 'face']:\n",
    "    if data_name == 'adult':\n",
    "        cfs = pd.read_csv(\"Results/adult_manifold_results.csv\")\n",
    "    elif data_name == 'give_me_some_credit':\n",
    "        cfs = pd.read_csv(\"Results/give_me_some_credit_manifold_results.csv\")\n",
    "    elif data_name == 'compas':\n",
    "        cfs = pd.read_csv(\"Results/compas_manifold_results.csv\")\n",
    "    factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "    test_factual = factuals.iloc[:100]\n",
    "\n",
    "    cfs.rename(columns={'Unnamed: 0': 'index'}, inplace=True)\n",
    "    cfs.set_index(['index'], inplace=True)\n",
    "\n",
    "    df_cfs = cfs[cfs['method'] == method].drop(['method',\t'data'], axis=1)\n",
    "\n",
    "    nan_idx = df_cfs.index[df_cfs.isnull().any(axis=1)]\n",
    "\n",
    "    output_factuals = test_factual.copy()\n",
    "    output_counterfactuals = df_cfs.copy()\n",
    "\n",
    "    output_factuals = output_factuals.drop(index=nan_idx)\n",
    "    output_counterfactuals = output_counterfactuals.drop(index=nan_idx)\n",
    "\n",
    "    factual_without_nans = output_factuals\n",
    "    counterfactuals_without_nans = output_counterfactuals\n",
    "\n",
    "\n",
    "    cols = dataset.df.columns\n",
    "    cols.drop(dataset.target)\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=5).fit(factual_without_nans[cols].values)\n",
    "\n",
    "    for i, row in counterfactuals_without_nans[cols].iterrows():\n",
    "        knn = nbrs.kneighbors(row.values.reshape((1, -1)), 5, return_distance=True)[0]\n",
    "        \n",
    "        results.append(np.mean(knn))\n",
    "final_results['feasibility'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "temp = final_results[['L0', 'L1', 'L2',  'feasibility', 'violations', 'validity', 'prediction']]#.groupby(['method']).mean()\n",
    "cfs.dropna(inplace=True)\n",
    "temp = pd.concat([temp, dataset.inverse_transform(cfs)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv(f\"/nr/samba/user/anr/pkg/MCCE_Python/Results/{data_name}_mcce_results_k_10000_n_100.csv\", index_col=0)\n",
    "\n",
    "results['data'] = data_name\n",
    "results['method'] = 'mcce'\n",
    "results.rename(columns={'violation': 'violations'}, inplace=True)\n",
    "\n",
    "preds = ml_model.predict_proba(results)\n",
    "new_preds = []\n",
    "for x in preds:\n",
    "    new_preds.append(x[1])\n",
    "results['prediction'] = new_preds\n",
    "results = dataset.inverse_transform(results)\n",
    "results.head(1)\n",
    "\n",
    "results['validity'] = np.where(np.asarray(new_preds) >= 0.5, 1, 0)\n",
    "\n",
    "# results.loc[263]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.concat([temp, results[temp.columns]])\n",
    "\n",
    "temp2 = factuals.copy()\n",
    "preds = ml_model.predict_proba(temp2)\n",
    "new_preds = []\n",
    "for x in preds:\n",
    "    new_preds.append(x[1])\n",
    "temp2['prediction'] = new_preds\n",
    "temp2 = dataset.inverse_transform(temp2)\n",
    "temp2.head(1)\n",
    "temp2['L0'] = np.nan\n",
    "temp2['L1'] = np.nan\n",
    "temp2['L2'] = np.nan\n",
    "temp2['validity'] = np.nan\n",
    "temp2['violations'] = np.nan\n",
    "temp2['feasibility'] = np.nan\n",
    "temp2['time (seconds)'] = np.nan\n",
    "temp2['method'] = 'original'\n",
    "temp2['data'] = data_name\n",
    "\n",
    "temp = pd.concat([temp, temp2.iloc[0:100][temp.columns]], axis=0)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.read_csv(f\"/nr/samba/user/anr/pkg/MCCE_Python/Results/{data_name}_baseline_results_n_100.csv\", index_col=0)\n",
    "# results['data'] = data_name\n",
    "# results['method'] = 'baseline'\n",
    "# results.rename(columns={'violation': 'violations'}, inplace=True)\n",
    "\n",
    "# preds = ml_model.predict_proba(results)\n",
    "# new_preds = []\n",
    "# for x in preds:\n",
    "#     new_preds.append(x[1])\n",
    "# results['prediction'] = new_preds\n",
    "# results = dataset.inverse_transform(results)\n",
    "# results.head(1)\n",
    "\n",
    "# results['validity'] = np.where(np.asarray(new_preds) >= 0.5, 1, 0)\n",
    "# results[temp.columns]\n",
    "# temp = pd.concat([temp, results[temp.columns]])\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_name == 'give_me_some_credit':\n",
    "    cols = ['method', 'data', 'prediction', 'L0', 'L1', 'L2', 'feasibility', 'violations', 'validity', 'time (seconds)'] + temp.columns[9:-1].to_list()\n",
    "    temp = temp[cols]\n",
    "elif data_name == 'adult':\n",
    "    cols = ['method', 'data', 'prediction', 'L0', 'L1', 'L2', 'feasibility', 'violations', 'validity', 'time (seconds)'] + temp.columns[9:16].to_list() + temp.columns[17:].to_list()\n",
    "    temp = temp[cols]\n",
    "temp.to_csv(f\"Final_results/{data_name}_results_mcce_and_carla_K_10000_n_100.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To get Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"Final_results/adult_results_mcce_and_carla_K_10000_n_100.csv\", index_col=0)\n",
    "\n",
    "to_write = temp[['method', 'L0', 'L2', 'feasibility', 'violations', 'validity', 'time (seconds)']].groupby(['method']).mean()\n",
    "\n",
    "to_write.reset_index(inplace=True)\n",
    "\n",
    "CE_N = temp.groupby(['method']).size().reset_index().rename(columns={0: 'CE_N'})\n",
    "to_write = pd.concat([to_write, CE_N.CE_N], axis=1)\n",
    "\n",
    "# to_write.sort_values(['method'], inplace=True, ascending=False)\n",
    "to_write = to_write[['method', 'L0', 'L2', 'feasibility', 'violations', 'validity', 'CE_N', 'time (seconds)']]\n",
    "\n",
    "print(to_write.to_latex(index=False, float_format=\"%.2f\", ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"Final_results/give_me_some_credit_results_mcce_and_carla_K_10000_n_100.csv\", index_col=0)\n",
    "\n",
    "to_write = temp[['method', 'L0', 'L2', 'feasibility', 'violations', 'validity', 'time (seconds)']].groupby(['method']).mean()\n",
    "\n",
    "to_write.reset_index(inplace=True)\n",
    "\n",
    "CE_N = temp.groupby(['method']).size().reset_index().rename(columns={0: 'CE_N'})\n",
    "to_write = pd.concat([to_write, CE_N.CE_N], axis=1)\n",
    "\n",
    "# to_write.sort_values(['method'], inplace=True, ascending=False)\n",
    "to_write = to_write[['method', 'L0', 'L2', 'feasibility', 'violations', 'validity', 'CE_N', 'time (seconds)']]\n",
    "\n",
    "print(to_write.to_latex(index=False, float_format=\"%.2f\", ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To get Adult examples in table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>data</th>\n",
       "      <th>prediction</th>\n",
       "      <th>L0</th>\n",
       "      <th>L1</th>\n",
       "      <th>L2</th>\n",
       "      <th>feasibility</th>\n",
       "      <th>violations</th>\n",
       "      <th>validity</th>\n",
       "      <th>time (seconds)</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>income</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>native-country</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>relationship</th>\n",
       "      <th>sex</th>\n",
       "      <th>workclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cchvae</td>\n",
       "      <td>adult</td>\n",
       "      <td>0.693449</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.691737</td>\n",
       "      <td>4.141263</td>\n",
       "      <td>0.929137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.685519</td>\n",
       "      <td>38.764985</td>\n",
       "      <td>189644.462285</td>\n",
       "      <td>10.111844</td>\n",
       "      <td>3652.984470</td>\n",
       "      <td>172.409726</td>\n",
       "      <td>40.223185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Married</td>\n",
       "      <td>US</td>\n",
       "      <td>Managerial-Specialist</td>\n",
       "      <td>White</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cem-vae</td>\n",
       "      <td>adult</td>\n",
       "      <td>0.500259</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.410045</td>\n",
       "      <td>2.039343</td>\n",
       "      <td>1.113540</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.218853</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>190709.000094</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10303.477725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.999999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Non-Married</td>\n",
       "      <td>US</td>\n",
       "      <td>Other</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>clue</td>\n",
       "      <td>adult</td>\n",
       "      <td>0.773839</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.803834</td>\n",
       "      <td>2.141725</td>\n",
       "      <td>1.477626</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>354.790007</td>\n",
       "      <td>10.527289</td>\n",
       "      <td>398961.583832</td>\n",
       "      <td>9.570491</td>\n",
       "      <td>10724.602753</td>\n",
       "      <td>-62.028129</td>\n",
       "      <td>49.267808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Non-Married</td>\n",
       "      <td>US</td>\n",
       "      <td>Other</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>crud</td>\n",
       "      <td>adult</td>\n",
       "      <td>0.945782</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.415565</td>\n",
       "      <td>1.386162</td>\n",
       "      <td>1.207662</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1145.259907</td>\n",
       "      <td>50.366662</td>\n",
       "      <td>147878.430972</td>\n",
       "      <td>16.521214</td>\n",
       "      <td>8414.476454</td>\n",
       "      <td>-30.494723</td>\n",
       "      <td>41.116929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Married</td>\n",
       "      <td>US</td>\n",
       "      <td>Managerial-Specialist</td>\n",
       "      <td>White</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>face</td>\n",
       "      <td>adult</td>\n",
       "      <td>0.509658</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.497612</td>\n",
       "      <td>3.072894</td>\n",
       "      <td>0.492528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>955.889991</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>38948.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3103.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Married</td>\n",
       "      <td>US</td>\n",
       "      <td>Other</td>\n",
       "      <td>White</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mcce</td>\n",
       "      <td>adult</td>\n",
       "      <td>0.929648</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.591622</td>\n",
       "      <td>0.176258</td>\n",
       "      <td>0.055145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.505169</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>274545.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>34095.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.929648</td>\n",
       "      <td>Non-Married</td>\n",
       "      <td>US</td>\n",
       "      <td>Other</td>\n",
       "      <td>Non-White</td>\n",
       "      <td>Non-Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>original</td>\n",
       "      <td>adult</td>\n",
       "      <td>0.015605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>266015.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Non-Married</td>\n",
       "      <td>US</td>\n",
       "      <td>Other</td>\n",
       "      <td>Non-White</td>\n",
       "      <td>Non-Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>baseline</td>\n",
       "      <td>adult</td>\n",
       "      <td>0.926050</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.693092</td>\n",
       "      <td>1.236643</td>\n",
       "      <td>0.386175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.057837</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>273701.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>34095.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.926050</td>\n",
       "      <td>Non-Married</td>\n",
       "      <td>US</td>\n",
       "      <td>Managerial-Specialist</td>\n",
       "      <td>Non-White</td>\n",
       "      <td>Non-Husband</td>\n",
       "      <td>Male</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      method   data  prediction    L0        L1        L2  feasibility  \\\n",
       "31    cchvae  adult    0.693449  11.0  4.691737  4.141263     0.929137   \n",
       "31   cem-vae  adult    0.500259   7.0  2.410045  2.039343     1.113540   \n",
       "31      clue  adult    0.773839   8.0  2.803834  2.141725     1.477626   \n",
       "31      crud  adult    0.945782  13.0  3.415565  1.386162     1.207662   \n",
       "31      face  adult    0.509658   8.0  3.497612  3.072894     0.492528   \n",
       "31      mcce  adult    0.929648   3.0  0.591622  0.176258     0.055145   \n",
       "31  original  adult    0.015605   NaN       NaN       NaN          NaN   \n",
       "31  baseline  adult    0.926050   4.0  1.693092  1.236643     0.386175   \n",
       "\n",
       "    violations  validity  time (seconds)        age         fnlwgt  \\\n",
       "31         1.0       1.0       85.685519  38.764985  189644.462285   \n",
       "31         1.0       1.0       81.218853  23.000000  190709.000094   \n",
       "31         1.0       1.0      354.790007  10.527289  398961.583832   \n",
       "31         1.0       1.0     1145.259907  50.366662  147878.430972   \n",
       "31         1.0       1.0      955.889991  35.000000   38948.000000   \n",
       "31         0.0       1.0      107.505169  20.000000  274545.000000   \n",
       "31         NaN       NaN             NaN  20.000000  266015.000000   \n",
       "31         0.0       1.0       17.057837  20.000000  273701.000000   \n",
       "\n",
       "    education-num  capital-gain  capital-loss  hours-per-week    income  \\\n",
       "31      10.111844   3652.984470    172.409726       40.223185  1.000000   \n",
       "31      12.000000  10303.477725      0.000000       51.999999  1.000000   \n",
       "31       9.570491  10724.602753    -62.028129       49.267808  1.000000   \n",
       "31      16.521214   8414.476454    -30.494723       41.116929  1.000000   \n",
       "31      11.000000   3103.000000      0.000000       40.000000  1.000000   \n",
       "31      10.000000  34095.000000      0.000000       20.000000  0.929648   \n",
       "31      10.000000      0.000000      0.000000       44.000000  0.000000   \n",
       "31      10.000000  34095.000000      0.000000       10.000000  0.926050   \n",
       "\n",
       "   marital-status native-country             occupation       race  \\\n",
       "31        Married             US  Managerial-Specialist      White   \n",
       "31    Non-Married             US                  Other      White   \n",
       "31    Non-Married             US                  Other      White   \n",
       "31        Married             US  Managerial-Specialist      White   \n",
       "31        Married             US                  Other      White   \n",
       "31    Non-Married             US                  Other  Non-White   \n",
       "31    Non-Married             US                  Other  Non-White   \n",
       "31    Non-Married             US  Managerial-Specialist  Non-White   \n",
       "\n",
       "   relationship   sex    workclass  \n",
       "31      Husband  Male      Private  \n",
       "31  Non-Husband  Male  Non-Private  \n",
       "31  Non-Husband  Male      Private  \n",
       "31      Husband  Male      Private  \n",
       "31      Husband  Male      Private  \n",
       "31  Non-Husband  Male      Private  \n",
       "31  Non-Husband  Male      Private  \n",
       "31  Non-Husband  Male      Private  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "temp = pd.read_csv(\"Final_results/adult_results_mcce_and_carla_K_10000_n_100.csv\", index_col=0)\n",
    "\n",
    "# cols = ['Method', 'Pred', 'Age', 'Work Class', 'FNLWGT', 'Educat.', 'Mar. Stat.', 'Relat.', 'Cap. Gain', 'Cap. Loss', 'Hr.', 'Co.']\n",
    "\n",
    "# cols = ['method', 'prediction', 'age', 'workclass', 'fnlwgt', 'education-num', 'marital-status', 'relationship', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
    "\n",
    "to_write = temp.loc[31]\n",
    "# to_write.columns = cols\n",
    "# to_write.sort_values(['Method'], inplace=True, ascending=False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "to_write\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# print(to_write.Pred.to_latex(index=False, float_format=\"%.2f\", ))\n",
    "feature = 'marital-status'\n",
    "dct = {'Married': 'M', 'Non-Married': 'NM'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "feature = 'native-country'\n",
    "dct = {'Non-US': 'NUS', 'US': 'US'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "feature = 'occupation'\n",
    "dct = {'Managerial-Specialist': 'MS', 'Other': 'O'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "feature = 'race'\n",
    "dct = {'White': 'W', 'Non-White': 'NW'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "feature = 'relationship'\n",
    "dct = {'Husband': 'H', 'Non-Husband': 'NH'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "feature = 'sex'\n",
    "dct = {'Male': 'M'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]\n",
    "\n",
    "\n",
    "feature = 'workclass'\n",
    "dct = {'Self-emp-not-inc': 'SENI', 'Private': 'P', 'Non-Private': 'NP'}\n",
    "to_write[feature] = [dct[item] for item in to_write[feature]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrlllllll}\n",
      "\\toprule\n",
      "   method &  age &  fnlwgt &  education-num &  capital-gain &  capital-loss &  hours-per-week & marital-status & native-country & occupation & race & relationship & sex & workclass \\\\\n",
      "\\midrule\n",
      "   cchvae &   39 &  189644 &             10 &          3653 &           172 &              40 &              M &             US &         MS &    W &            H &   M &         P \\\\\n",
      "  cem-vae &   23 &  190709 &             12 &         10303 &             0 &              52 &             NM &             US &          O &    W &           NH &   M &        NP \\\\\n",
      "     clue &   11 &  398962 &             10 &         10725 &           -62 &              49 &             NM &             US &          O &    W &           NH &   M &         P \\\\\n",
      "     crud &   50 &  147878 &             17 &          8414 &           -30 &              41 &              M &             US &         MS &    W &            H &   M &         P \\\\\n",
      "     face &   35 &   38948 &             11 &          3103 &             0 &              40 &              M &             US &          O &    W &            H &   M &         P \\\\\n",
      "     mcce &   20 &  274545 &             10 &         34095 &             0 &              20 &             NM &             US &          O &   NW &           NH &   M &         P \\\\\n",
      " original &   20 &  266015 &             10 &             0 &             0 &              44 &             NM &             US &          O &   NW &           NH &   M &         P \\\\\n",
      " baseline &   20 &  273701 &             10 &         34095 &             0 &              10 &             NM &             US &         MS &   NW &           NH &   M &         P \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['method', 'age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', \\\n",
    "       'hours-per-week', 'marital-status', 'native-country', \\\n",
    "       'occupation', 'race', 'relationship', 'sex', 'workclass']\n",
    "\n",
    "print(to_write[cols].to_latex(index=False, float_format=\"%.0f\", ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To get GMC examples in table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"Final_results/give_me_some_credit_results_mcce_and_carla_K_10000_n_100.csv\", index_col=0)\n",
    "temp.loc[263]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['method', 'prediction', 'age', 'RevolvingUtilizationOfUnsecuredLines', 'NumberOfTime30-59DaysPastDueNotWorse', 'DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']\n",
    "\n",
    "to_write = temp[cols].loc[263]\n",
    "\n",
    "cols = ['Method', 'Pred', 'Age', 'Unsec. Lines', 'Nb Days Past 30', 'Debt Ratio', 'Month Inc.', 'Nb Credit Lines', 'Nb Times 90 Days Late', 'Nb Real Estate Loans', 'Nb Times 60 Days Past', 'Nb Dep.']\n",
    "\n",
    "to_write.columns = cols\n",
    "# to_write.sort_values(['Method'], inplace=True, ascending=False)\n",
    "\n",
    "# print(to_write.to_latex(index=False, float_format=\"%.0f\", ))\n",
    "\n",
    "print(to_write.to_latex(index=False, float_format=\"%.2f\", ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [ 'age', 'RevolvingUtilizationOfUnsecuredLines', 'NumberOfTime30-59DaysPastDueNotWorse','DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']\n",
    "metric_names = ['method', 'L0', 'L1', 'violations', 'validity', 'prediction']\n",
    "\n",
    "temp = dataset.inverse_transform(final_results.dropna()[features])\n",
    "temp = pd.concat([final_results[metric_names], temp], axis=1)\n",
    "# temp.sort_values(temp.index.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcce_results = pd.read_csv(f\"/nr/samba/user/anr/pkg/MCCE_Python/give_me_some_credit_mcce_results_k_10000.csv\")\n",
    "mcce_results.rename(columns={'Unnamed: 0': 'index'}, inplace=True)\n",
    "mcce_results.set_index(['index'], inplace=True)\n",
    "\n",
    "predictions = ml_model.predict_proba(mcce_results)\n",
    "temp3 = []\n",
    "for x in predictions:\n",
    "    temp3.append(x[1]) #  >= 0.5\n",
    "    \n",
    "# temp.index = final_results.index\n",
    "mcce_results['prediction'] = temp3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcce_results.sort_values(mcce_results.index.name, inplace=True)\n",
    "mcce_results['method'] = 'mcce'\n",
    "mcce_results.rename(columns={'success': 'validity', 'violation': 'violations'}, inplace=True)\n",
    "temp_mcce = dataset.inverse_transform(mcce_results.dropna()[features])\n",
    "temp_mcce = pd.concat([mcce_results[metric_names], temp_mcce], axis=1)\n",
    "# temp_mcce.sort_values(temp_mcce.index.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "temp2 = pd.concat([temp, temp_mcce], axis=0)\n",
    "\n",
    "temp2.sort_values(temp2.index.name)\n",
    "\n",
    "features = ['method', 'prediction', 'age', 'RevolvingUtilizationOfUnsecuredLines', 'NumberOfTime30-59DaysPastDueNotWorse','DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']\n",
    "\n",
    "temp2.loc[263][features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "dataset.inverse_transform(factuals.iloc[3:4])[['age', 'RevolvingUtilizationOfUnsecuredLines', 'NumberOfTime30-59DaysPastDueNotWorse','DebtRatio', 'MonthlyIncome', 'NumberOfOpenCreditLinesAndLoans', 'NumberOfTimes90DaysLate', 'NumberRealEstateLoansOrLines', 'NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfDependents']]\n",
    "\n",
    "ml_model.predict_proba(factuals.iloc[3:4])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea38de303447ace9d448c28089670fa84711b12cac6767c435896f96584513e1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('carla_github')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
