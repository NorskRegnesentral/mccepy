{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "n_test = 100\n",
    "K = 10000\n",
    "\n",
    "import torch\n",
    "\n",
    "from mcce import MCCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Python-MIP package version 1.12.0 [model.py <module>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/ipykernel_launcher.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "from carla.data.catalog import OnlineCatalog\n",
    "import pandas as pd\n",
    "\n",
    "train_path = \"/nr/samba/user/anr/pkg/MCCE/Datasets/Adult/adult.data\"\n",
    "test_path = \"/nr/samba/user/anr/pkg/MCCE/Datasets/Adult/adult.test\"\n",
    "train = pd.read_csv(train_path, sep=\", \", header=None, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'])\n",
    "test = pd.read_csv(test_path, skiprows=1, sep=\", \", header=None, names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'])\n",
    "\n",
    "df = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "df.to_csv(\"/nr/samba/user/anr/pkg/MCCE/Datasets/Adult/Adult_train_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'>50K': '>50K', '>50K.': '>50K', '<=50K': '<=50K', '<=50K.': '<=50K'}\n",
    "\n",
    "df['income'] = [mapping[item] for item in df['income']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'workclass'\n",
    "d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "for i, ind in enumerate(d):\n",
    "    d[i] = i\n",
    "mapping = d.to_dict()\n",
    "df[feature] = [mapping[item] for item in df[feature]]\n",
    "\n",
    "feature = 'education'\n",
    "d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "for i, ind in enumerate(d):\n",
    "    d[i] = i\n",
    "mapping = d.to_dict()\n",
    "df[feature] = [mapping[item] for item in df[feature]]\n",
    "\n",
    "feature = 'marital-status'\n",
    "d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "for i, ind in enumerate(d):\n",
    "    d[i] = i\n",
    "mapping = d.to_dict()\n",
    "df[feature] = [mapping[item] for item in df[feature]]\n",
    "\n",
    "feature = 'occupation'\n",
    "d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "for i, ind in enumerate(d):\n",
    "    d[i] = i\n",
    "mapping = d.to_dict()\n",
    "df[feature] = [mapping[item] for item in df[feature]]\n",
    "\n",
    "feature = 'relationship'\n",
    "d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "for i, ind in enumerate(d):\n",
    "    d[i] = i\n",
    "mapping = d.to_dict()\n",
    "df[feature] = [mapping[item] for item in df[feature]]\n",
    "\n",
    "feature = 'sex'\n",
    "d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "for i, ind in enumerate(d):\n",
    "    d[i] = i\n",
    "mapping = d.to_dict()\n",
    "df[feature] = [mapping[item] for item in df[feature]]\n",
    "\n",
    "feature = 'race'\n",
    "d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "for i, ind in enumerate(d):\n",
    "    d[i] = i\n",
    "mapping = d.to_dict()\n",
    "df[feature] = [mapping[item] for item in df[feature]]\n",
    "\n",
    "feature = 'native-country'\n",
    "d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "for i, ind in enumerate(d):\n",
    "    d[i] = i\n",
    "mapping = d.to_dict()\n",
    "df[feature] = [mapping[item] for item in df[feature]]\n",
    "\n",
    "feature = 'income'\n",
    "d = df.groupby([feature]).size().sort_values(ascending=False)\n",
    "for i, ind in enumerate(d):\n",
    "    d[i] = i\n",
    "mapping = d.to_dict()\n",
    "df[feature] = [mapping[item] for item in df[feature]]\n",
    "\n",
    "df.drop(['education'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['workclass', 'occupation', 'relationship', 'native-country']].groupby(by = 'workclass').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = ['age',\n",
    "    'fnlwgt',\n",
    "    'education-num',\n",
    "    'capital-gain',\n",
    "    'hours-per-week',\n",
    "    'capital-loss']\n",
    "\n",
    "categorical = ['marital-status',\n",
    "'native-country',\n",
    "'occupation',\n",
    "'race',\n",
    "'relationship',\n",
    "'sex',\n",
    "'workclass', \n",
    "'income']\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler().fit(df[continuous])\n",
    "df_scaled = scaler.transform(df[continuous])\n",
    "df_scaled = pd.DataFrame(df_scaled)\n",
    "df_scaled.columns = continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = pd.concat([df_scaled, df[categorical]], axis=1) # axis = 0 is index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.to_csv(\"/nr/samba/user/anr/pkg/MCCE/Datasets/Adult/for_CsvCatalog.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carla.data.catalog import CsvCatalog\n",
    "\n",
    "continuous = [\"age\", \"fnlwgt\", \"education-num\", \"capital-gain\", \"hours-per-week\", \"capital-loss\"]\n",
    "categorical = [\"marital-status\", \"native-country\", \"occupation\", \"race\", \"relationship\", \"sex\", \"workclass\"]\n",
    "immutable = [\"age\", \"sex\"]\n",
    "\n",
    "dataset = CsvCatalog(file_path=\"/nr/samba/user/anr/pkg/MCCE/Datasets/Adult/for_CsvCatalog.csv\",\n",
    "                     continuous=continuous,\n",
    "                     categorical=categorical,\n",
    "                     immutables=immutable,\n",
    "                     target='income',\n",
    "                     scaling_method=None,\n",
    "                     encoding_method=None,\n",
    "                     )\n",
    "\n",
    "# dataset.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balance on test set 0.23985149190576288, balance on test set 0.23757268037015805\n",
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/carla/models/catalog/ANN_TORCH/model_ann.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4695 Acc: 0.7750\n",
      "\n",
      "test Loss: 0.4200 Acc: 0.8035\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.4128 Acc: 0.8104\n",
      "\n",
      "test Loss: 0.4063 Acc: 0.8108\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.3965 Acc: 0.8183\n",
      "\n",
      "test Loss: 0.3948 Acc: 0.8171\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.3832 Acc: 0.8241\n",
      "\n",
      "test Loss: 0.3772 Acc: 0.8281\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.3725 Acc: 0.8284\n",
      "\n",
      "test Loss: 0.3705 Acc: 0.8275\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.3616 Acc: 0.8323\n",
      "\n",
      "test Loss: 0.3593 Acc: 0.8345\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.3553 Acc: 0.8347\n",
      "\n",
      "test Loss: 0.3553 Acc: 0.8355\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.3453 Acc: 0.8405\n",
      "\n",
      "test Loss: 0.3528 Acc: 0.8345\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.3451 Acc: 0.8405\n",
      "\n",
      "test Loss: 0.3481 Acc: 0.8374\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.3454 Acc: 0.8391\n",
      "\n",
      "test Loss: 0.3518 Acc: 0.8370\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.3379 Acc: 0.8427\n",
      "\n",
      "test Loss: 0.3414 Acc: 0.8413\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.3360 Acc: 0.8438\n",
      "\n",
      "test Loss: 0.3409 Acc: 0.8405\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.3352 Acc: 0.8443\n",
      "\n",
      "test Loss: 0.3393 Acc: 0.8424\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.3334 Acc: 0.8450\n",
      "\n",
      "test Loss: 0.3465 Acc: 0.8338\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.3307 Acc: 0.8450\n",
      "\n",
      "test Loss: 0.3374 Acc: 0.8425\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.3329 Acc: 0.8450\n",
      "\n",
      "test Loss: 0.3369 Acc: 0.8422\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.3306 Acc: 0.8466\n",
      "\n",
      "test Loss: 0.3677 Acc: 0.8353\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.3303 Acc: 0.8467\n",
      "\n",
      "test Loss: 0.3354 Acc: 0.8438\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.3296 Acc: 0.8469\n",
      "\n",
      "test Loss: 0.3350 Acc: 0.8415\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.3282 Acc: 0.8486\n",
      "\n",
      "test Loss: 0.3372 Acc: 0.8399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from carla.models.catalog import MLModelCatalog\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "ml_model = MLModelCatalog(\n",
    "        dataset, \n",
    "        model_type=\"ann\", \n",
    "        load_online=False, \n",
    "        backend=\"pytorch\"\n",
    "    )\n",
    "\n",
    "\n",
    "ml_model.train(\n",
    "learning_rate=0.002,\n",
    "epochs=20,\n",
    "batch_size=1024,\n",
    "hidden_size=[18, 9, 3],\n",
    "force_train=True, # don't forget to add this or it might load an older model from disk\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting MCCE model...\n",
      "Generating counterfactuals with MCCE...\n"
     ]
    }
   ],
   "source": [
    "from carla.models.negative_instances import predict_negative_instances\n",
    "\n",
    "factuals = predict_negative_instances(ml_model, dataset.df)\n",
    "test_factual = factuals.iloc[:n_test]\n",
    "# test_factual_inverse = dataset.inverse_transform(test_factual)\n",
    "\n",
    "y_col = dataset.target\n",
    "features_and_response = dataset.df.columns\n",
    "cont_feat = dataset.continuous\n",
    "cat_feat = [x for x in features_and_response if x not in cont_feat] #  these have new names since encode_normalize_order_factuals()\n",
    "\n",
    "fixed_features = ['age', 'sex']\n",
    "\n",
    "#  Create dtypes for MCCE()\n",
    "dtypes = dict([(x, \"float\") for x in cont_feat])\n",
    "for x in cat_feat:\n",
    "    dtypes[x] = \"category\"\n",
    "df = (dataset.df).astype(dtypes)\n",
    "\n",
    "# (3) Fit MCCE object\n",
    "print(\"Fitting MCCE model...\")\n",
    "mcce = MCCE(fixed_features=fixed_features, model=ml_model, seed=1)\n",
    "mcce.fit(df.drop(y_col, axis=1), dtypes)\n",
    "print(\"Generating counterfactuals with MCCE...\")\n",
    "synth_df = mcce.generate(test_factual.drop(y_col, axis=1), k=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postprocessing counterfactuals with MCCE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nr/samba/user/anr/anaconda3/envs/carla_github/lib/python3.7/site-packages/carla/models/catalog/ANN_TORCH/model_ann.py:56: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "# (4) Postprocess generated counterfactuals\n",
    "print(\"Postprocessing counterfactuals with MCCE...\")\n",
    "mcce.postprocess(df, synth_df, test_factual, y_col, scaler=dataset.inverse_transform, cutoff=0.5)\n",
    "\n",
    "# 20 minutes for give_me_some_credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.909090909090909\n",
      "4.005146960989371\n",
      "13.61811506850455\n"
     ]
    }
   ],
   "source": [
    "# print(mcce.results_sparse.)\n",
    "print(mcce.results_sparse.L0.mean())\n",
    "print(mcce.results_sparse.L1.mean())\n",
    "print(mcce.results_sparse.L2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "141    1\n",
       "32     1\n",
       "34     1\n",
       "35     1\n",
       "36     1\n",
       "      ..\n",
       "92     1\n",
       "93     1\n",
       "95     1\n",
       "97     1\n",
       "0      1\n",
       "Length: 99, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_sparse = mcce.results_sparse\n",
    "results_sparse.index.rename('index', inplace=True)\n",
    "results_sparse.groupby('index').size().sort_values(ascending=False)\n",
    "#results_sparse.loc[64].iloc[0]#[[dataset.categorical + dataset.continuous]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_decoded_cfs = pd.DataFrame(scaler.inverse_transform(df_cfs.copy()[continuous]))\n",
    "# df_decoded_cfs.columns = continuous\n",
    "# df_decoded_cfs.index = df_cfs.index\n",
    "# df_decoded_cfs = pd.concat([df_decoded_cfs, df_cfs.copy()[categorical]], axis=1)\n",
    "\n",
    "# df_factuals = pd.DataFrame(scaler.inverse_transform(test_repeated.copy()[continuous]))\n",
    "# df_factuals.columns = continuous\n",
    "# df_factuals.index = test_repeated.index\n",
    "# df_factuals = pd.concat([df_factuals, test_repeated.copy()[categorical]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea38de303447ace9d448c28089670fa84711b12cac6767c435896f96584513e1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('carla_github')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
